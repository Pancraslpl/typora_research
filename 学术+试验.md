#                  一、Python相关知识

## 1.1 Python程序问题集锦

<img src="E:\个人文件汇总\照片类\手机相册备份\备份\DCIM\100CLOUD\IMG_4680.PNG" alt="IMG_4680" style="zoom:67%;" />

### （1）**Python中消除futureWarning问题**

```python
from warnings import simplefilter
simplefilter(action='ignore', category=FutureWarning)
```

### （2）回调函数

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220924151814307.png" alt="image-20220924151814307" style="zoom:50%;" />

### （3）python中的format函数

1. **填充**

   通过位置来填充字符串

   ```python
   print('he1lo {0} i am {1}'.format('Kevin','Tom'))
    
   print('hello {} i am {}'.format('Kevin','Tom'))
    
   print('hello {0} i am {1} . my name is {0}'.format('Kevin','Tom'))
    
   #输出
   he1lo Kevin i am Tom
   hello Kevin i am Tom
   hello Kevin i am Tom . my name is Kevin
   ```

### （4）python中的class类及相关的_ _init_ _(self,  parameter1, parameter2) 函数

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220926094333119.png" alt="image-20220926094333119" style="zoom:67%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220926094405381.png" alt="image-20220926094405381" style="zoom:67%;" />

### (5) range函数

```python
>>> range(0, 30, 5) # 步长为 5
[0, 5, 10, 15, 20, 25]
```

### (6) matplotlib画图的所有问题集锦

​      **一张图把matplotlib的各种参数解释清楚**

<img src="https://img-blog.csdnimg.cn/20210531162903927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjgxNTY4,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />

#### 1. 当plot图中的中文文字无法显示时：

 添加两行代码：

```python
import matplotlib as plt
plt.rcParams['font.sans-serif'] = ['SimHei']  # 显示中文标签
plt.rcParams['axes.unicode_minus'] = False  # 这两行需要手动设置
```

#### 2. 画图的整体逻辑

首先，建立一个画板，fig=figure(),如果不写的话，默认figure(1),只有建立了画板之后才可以在上面做图；

接下来需要确定画的图的坐标，即，fig.subplot()，如果不写这句代码的话默认创建subplot(111);

最后只需要fig.plot(x,y)将图画出来。

#### 3. 二维平面图（所有图）

（1）简单的折线图：

<img src="https://img-blog.csdnimg.cn/img_convert/723ad185e1d3d4b51244a4f20c22a42d.png" alt="img" style="zoom:33%;" />

（2）Y轴范围不一致的折线图

<img src="https://img-blog.csdnimg.cn/img_convert/5c4f3cc446b5ae579fe6ddde4adb3929.png" alt="img" style="zoom:33%;" />

（3）子图的画法

<img src="https://img-blog.csdnimg.cn/img_convert/fe7bb725a5270388ec6dd7e95dcc71c3.png" alt="img" style="zoom:33%;" />

（4）简单的柱状图

<img src="https://img-blog.csdnimg.cn/img_convert/e7bbed30101a015009b20a092025b092.png" alt="img" style="zoom:33%;" />

（5）水平方向的柱状图

<img src="https://img-blog.csdnimg.cn/img_convert/7e4edb46768de204d87dab961bf31016.png" alt="img" style="zoom:33%;" />

（6）更高级的柱状图

<img src="https://img-blog.csdnimg.cn/img_convert/fcfacc31029148dec6094049b1b673c3.png" alt="img" style="zoom:33%;" />

（7）类表格图形

<img src="https://img-blog.csdnimg.cn/img_convert/747d133c79d543d03cd0060c34577c3d.png" alt="img" style="zoom:33%;" />

（8）直方图

<img src="https://img-blog.csdnimg.cn/img_convert/ddb96f0ad012653ccf09861f8b39a7f3.png" alt="img" style="zoom:33%;" />

（9）饼图

<img src="https://img-blog.csdnimg.cn/img_convert/bee130eae8fc68cfd15319115a147d19.png" alt="img" style="zoom:33%;" />

（10）散点图

<img src="https://img-blog.csdnimg.cn/img_convert/e2a8195b60d958170cfdea4d493b4ab0.png" alt="img" style="zoom:33%;" />

（11）雷达图

<img src="https://img-blog.csdnimg.cn/img_convert/1143583aa9f18b2481aaf8a53aec00b1.png" alt="img" style="zoom:33%;" />

（12）三维散点图

<img src="https://img-blog.csdnimg.cn/img_convert/0871b0ece208540fc04fddc8f0a731f8.png" alt="img" style="zoom:33%;" />

（13）三维折线图

<img src="https://img-blog.csdnimg.cn/img_convert/a7fab13e4f0b567b8fe04f036546ebe8.png" alt="img" style="zoom:33%;" />

（14）三维柱状图

<img src="https://img-blog.csdnimg.cn/img_convert/f7a1c2b93b5e915402421c9df7087b3d.png" alt="img" style="zoom:33%;" />

（15）图形填充

<img src="https://img-blog.csdnimg.cn/img_convert/63f777e403488560ffadaa28bc933ab4.png" alt="img" style="zoom:33%;" />

**代码：**

```python
# _*_ coding: utf-8 _*_

"""
python_visual.py by xianhu
"""

import numpy as np
import matplotlib
import matplotlib.mlab as mlab
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from mpl_toolkits.mplot3d import Axes3D

# 解决中文乱码问题
myfont = fm.FontProperties(fname="/Library/Fonts/Songti.ttc", size=14)
matplotlib.rcParams["axes.unicode_minus"] = False


def simple_plot():
    """
    simple plot
    """
    # 生成测试数据
    x = np.linspace(-np.pi, np.pi, 256, endpoint=True)
    y_cos, y_sin = np.cos(x), np.sin(x)

    # 生成画布，并设定标题
    plt.figure(figsize=(8, 6), dpi=80)
    plt.title("简单曲线图", fontproperties=myfont)
    plt.grid(True)

    # 设置X轴
    plt.xlabel("X轴", fontproperties=myfont)
    plt.xlim(-4.0, 4.0)
    plt.xticks(np.linspace(-4, 4, 9, endpoint=True))

    # 设置Y轴
    plt.ylabel("Y轴", fontproperties=myfont)
    plt.ylim(-1.0, 1.0)
    plt.yticks(np.linspace(-1, 1, 9, endpoint=True))

    # 画两条曲线
    plt.plot(x, y_cos, "b--", linewidth=2.0, label="cos示例")
    plt.plot(x, y_sin, "g-", linewidth=2.0, label="sin示例")

    # 设置图例位置,loc可以为[upper, lower, left, right, center]
    plt.legend(loc="upper left", prop=myfont, shadow=True)

    # 图形显示
    plt.show()
    return
# simple_plot()


def simple_advanced_plot():
    """
    simple advanced plot
    """
    # 生成测试数据
    x = np.linspace(-np.pi, np.pi, 256, endpoint=True)
    y_cos, y_sin = np.cos(x), np.sin(x)

    # 生成画布, 并设定标题
    plt.figure(figsize=(8, 6), dpi=80)
    plt.title("复杂曲线图", fontproperties=myfont)
    plt.grid(True)

    # 画图的另外一种方式
    ax_1 = plt.subplot(111)
    ax_1.plot(x, y_cos, color="blue", linewidth=2.0, linestyle="--", label="左cos")
    ax_1.legend(loc="upper left", prop=myfont, shadow=True)

    # 设置Y轴(左边)
    ax_1.set_ylabel("左cos的y轴", fontproperties=myfont)
    ax_1.set_ylim(-1.0, 1.0)
    ax_1.set_yticks(np.linspace(-1, 1, 9, endpoint=True))

    # 画图的另外一种方式
    ax_2 = ax_1.twinx()
    ax_2.plot(x, y_sin, color="green", linewidth=2.0, linestyle="-", label="右sin")
    ax_2.legend(loc="upper right", prop=myfont, shadow=True)

    # 设置Y轴(右边)
    ax_2.set_ylabel("右sin的y轴", fontproperties=myfont)
    ax_2.set_ylim(-2.0, 2.0)
    ax_2.set_yticks(np.linspace(-2, 2, 9, endpoint=True))

    # 设置X轴(共同)
    ax_1.set_xlabel("x轴", fontproperties=myfont)
    ax_1.set_xlim(-4.0, 4.0)
    ax_1.set_xticks(np.linspace(-4, 4, 9, endpoint=True))

    # 图形显示
    plt.show()
    return
# simple_advanced_plot()


def subplot_plot():
    """
    subplot plot
    """
    # 子图的style列表
    style_list = ["g+-", "r*-", "b.-", "yo-"]

    # 依次画图
    for num in range(4):
        # 生成测试数据
        x = np.linspace(0.0, 2+num, num=10*(num+1))
        y = np.sin((5-num) * np.pi * x)

        # 子图的生成方式
        plt.subplot(2, 2, num+1)
        plt.title("子图 %d" % (num+1), fontproperties=myfont)
        plt.plot(x, y, style_list[num])

    # 图形显示
    plt.show()
    return
# subplot_plot()


def bar_plot():
    """
    bar plot
    """
    # 生成测试数据
    means_men = (20, 35, 30, 35, 27)
    means_women = (25, 32, 34, 20, 25)

    # 设置标题
    plt.title("柱状图", fontproperties=myfont)

    # 设置相关参数
    index = np.arange(len(means_men))
    bar_width = 0.35

    # 画柱状图
    plt.bar(index, means_men, width=bar_width, alpha=0.2, color="b", label="男生")
    plt.bar(index+bar_width, means_women, width=bar_width, alpha=0.8, color="r", label="女生")
    plt.legend(loc="upper right", prop=myfont, shadow=True)

    # 设置柱状图标示
    for x, y in zip(index, means_men):
        plt.text(x, y+0.3, y, ha="center", va="bottom")
    for x, y in zip(index, means_women):
        plt.text(x+bar_width, y+0.3, y, ha="center", va="bottom")

    # 设置刻度范围/坐标轴名称等
    plt.ylim(0, 45)
    plt.xlabel("分组Group", fontproperties=myfont)
    plt.ylabel("得分Scores", fontproperties=myfont)
    plt.xticks(index+(bar_width/2), ("A组", "B组", "C组", "D组", "E组"), fontproperties=myfont)

    # 图形显示
    plt.show()
    return
# bar_plot()


def barh_plot():
    """
    barh plot
    """
    # 生成测试数据
    means_men = (20, 35, 30, 35, 27)
    means_women = (25, 32, 34, 20, 25)

    # 设置标题
    plt.title("横向柱状图", fontproperties=myfont)

    # 设置相关参数
    index = np.arange(len(means_men))
    bar_height = 0.35

    # 画柱状图(水平方向)
    plt.barh(index, means_men, height=bar_height, alpha=0.2, color="b", label="Men")
    plt.barh(index+bar_height, means_women, height=bar_height, alpha=0.8, color="r", label="Women")
    plt.legend(loc="upper right", shadow=True)

    # 设置柱状图标示
    for x, y in zip(index, means_men):
        plt.text(y+0.3, x, y, ha="left", va="center")
    for x, y in zip(index, means_women):
        plt.text(y+0.3, x+bar_height, y, ha="left", va="center")

    # 设置刻度范围/坐标轴名称等
    plt.xlim(0, 45)
    plt.xlabel("Scores")
    plt.ylabel("Group")
    plt.yticks(index+(bar_height/2), ("A", "B", "C", "D", "E"))

    # 图形显示
    plt.show()
    return
# barh_plot()


def bar_advanced_plot():
    """
    bar advanced plot
    """
    # 生成测试数据
    means_men = np.array((20, 35, 30, 35, 27, 25, 32, 34, 20, 25))
    means_women = np.array((25, 32, 34, 20, 25, 20, 35, 30, 35, 27))

    # 设置标题
    plt.title("高级柱状图", fontproperties=myfont)

    # 设置相关参数
    index = np.arange(len(means_men))
    bar_width = 0.8

    # 画柱状图(两种:X轴以上/X轴以下)
    plt.bar(index, means_men, width=bar_width, alpha=0.4, color="b", label="Men")
    plt.bar(index, -means_women, width=bar_width, alpha=0.4, color="r", label="Women")

    # 画折线图(两种,和柱状图对应)
    plt.plot(index, means_men, marker="o", linestyle="-", color="r", label="Men line")
    plt.plot(index, -means_women, marker=".", linestyle="--", color="b", label="Women line")

    # 设置图形标示(两种,和柱状图对应)
    for x, y in zip(index, means_men):
        plt.text(x, y+1, y, ha="center", va="bottom")
    for x, y in zip(index, means_women):
        plt.text(x, -y-1, y, ha="center", va="top")

    # 设置Y轴和图例位置
    plt.ylim(-45, 80)
    plt.legend(loc="upper left", shadow=True)

    # 图形显示
    plt.show()
    return
# bar_advanced_plot()


def table_plot():
    """
    table plot
    """
    # 生成测试数据
    data = np.array([
        [1, 4, 2, 5, 2],
        [2, 1, 1, 3, 6],
        [5, 3, 6, 4, 1]
    ])

    # 设置标题
    plt.title("层次柱状图", fontproperties=myfont)

    # 设置相关参数
    index = np.arange(len(data[0]))
    color_index = ["r", "g", "b"]

    # 声明底部位置
    bottom = np.array([0, 0, 0, 0, 0])

    # 依次画图,并更新底部位置
    for i in range(len(data)):
        plt.bar(index, data[i], width=0.5, color=color_index[i], bottom=bottom, alpha=0.7, label="标签 %d" % i)
        bottom += data[i]

    # 设置图例位置
    plt.legend(loc="upper left", prop=myfont, shadow=True)

    # 图形显示
    plt.show()
    return
# table_plot()


def histograms_plot():
    """
    histograms plot
    """
    # 生成测试数据
    mu, sigma = 100, 15
    x = mu + sigma * np.random.randn(10000)

    # 设置标题
    plt.title("直方图", fontproperties=myfont)

    # 画直方图, 并返回相关结果
    n, bins, patches = plt.hist(x, bins=50, normed=1, cumulative=False, color="green", alpha=0.6, label="直方图")

    # 根据直方图返回的结果, 画折线图
    y = mlab.normpdf(bins, mu, sigma)
    plt.plot(bins, y, "r--", label="线条")

    # 设置图例位置
    plt.legend(loc="upper left", prop=myfont, shadow=True)

    # 图形显示
    plt.show()
    return
# histograms_plot()


def pie_plot():
    """
    pie plot
    """
    # 生成测试数据
    sizes = [15, 30, 45, 10]
    labels = ["Frogs", "中文", "Dogs", "Logs"]
    colors = ["yellowgreen", "gold", "lightskyblue", "lightcoral"]

    # 设置标题
    plt.title("饼图", fontproperties=myfont)

    # 设置突出参数
    explode = [0, 0.05, 0, 0]

    # 画饼状图
    patches, l_text, p_text = plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct="%1.1f%%", shadow=True, startangle=90)
    for text in l_text:
        text.set_fontproperties(myfont)
    plt.axis("equal")

    # 图形显示
    plt.show()
    return
# pie_plot()


def scatter_plot():
    """
    scatter plot
    """
    # 生成测试数据
    point_count = 1000
    x_index = np.random.random(point_count)
    y_index = np.random.random(point_count)

    # 设置标题
    plt.title("散点图", fontproperties=myfont)

    # 设置相关参数
    color_list = np.random.random(point_count)
    scale_list = np.random.random(point_count) * 100

    # 画散点图
    plt.scatter(x_index, y_index, s=scale_list, c=color_list, marker="o")

    # 图形显示
    plt.show()
    return
# scatter_plot()


def fill_plot():
    """
    fill plot
    """
    # 生成测试数据
    x = np.linspace(-2*np.pi, 2*np.pi, 1000, endpoint=True)
    y = np.sin(x)

    # 设置标题
    plt.title("填充图", fontproperties=myfont)

    # 画图
    plt.plot(x, y, color="blue", alpha=1.00)

    # 填充图形, plt.fill_between(x, y1, y2, where=None, *kwargs)
    plt.fill_between(x, 0, y, where=(y > 0), color="blue", alpha=0.25)
    plt.fill_between(x, 0, y, where=(y < 0), color="red", alpha=0.25)

    # 图形显示
    plt.show()
    return
# fill_plot()


def radar_plot():
    """
    radar plot
    """
    # 生成测试数据
    labels = np.array(["A组", "B组", "C组", "D组", "E组", "F组"])
    data = np.array([68, 83, 90, 77, 89, 73])
    theta = np.linspace(0, 2*np.pi, len(data), endpoint=False)

    # 数据预处理
    data = np.concatenate((data, [data[0]]))
    theta = np.concatenate((theta, [theta[0]]))

    # 画图方式
    plt.subplot(111, polar=True)
    plt.title("雷达图", fontproperties=myfont)

    # 设置"theta grid"/"radar grid"
    plt.thetagrids(theta*(180/np.pi), labels=labels, fontproperties=myfont)
    plt.rgrids(np.arange(20, 100, 20), labels=np.arange(20, 100, 20), angle=0)
    plt.ylim(0, 100)

    # 画雷达图,并填充雷达图内部区域
    plt.plot(theta, data, "bo-", linewidth=2)
    plt.fill(theta, data, color="red", alpha=0.25)

    # 图形显示
    plt.show()
    return
# radar_plot()


def three_dimension_scatter():
    """
    3d scatter plot
    """
    # 生成测试数据
    x = np.random.random(100)
    y = np.random.random(100)
    z = np.random.random(100)
    color = np.random.random(100)
    scale = np.random.random(100) * 100

    # 生成画布(两种形式)
    fig = plt.figure()
    fig.suptitle("三维散点图", fontproperties=myfont)

    # ax = fig.gca(projection="3d")
    ax = fig.add_subplot(111, projection="3d")

    # 画三维散点图
    ax.scatter(x, y, z, s=scale, c=color, marker=".")

    # 设置坐标轴图标
    ax.set_xlabel("X Label")
    ax.set_ylabel("Y Label")
    ax.set_zlabel("Z Label")

    # 设置坐标轴范围
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.set_zlim(0, 1)

    # 图形显示
    plt.show()
    return
# three_dimension_scatter()


def three_dimension_line():
    """
    3d line plot
    """
    # 生成测试数据
    x = np.linspace(0, 1, 1000)
    y = np.linspace(0, 1, 1000)
    z = np.sin(x * 2 * np.pi) / (y + 0.1)

    # 生成画布(两种形式)
    fig = plt.figure()
    ax = fig.gca(projection="3d", title="plot title")
    # ax = fig.add_subplot(111, projection="3d", title="plot title")

    # 画三维折线图
    ax.plot(x, y, z, color="red", linestyle="-")

    # 设置坐标轴图标
    ax.set_xlabel("X Label")
    ax.set_ylabel("Y Label")
    ax.set_zlabel("Z Label")

    # 图形显示
    plt.show()
    return
# three_dimension_line()


def three_dimension_bar():
    """
    3d bar plot
    """
    # 生成测试数据(位置数据)
    xpos = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    ypos = [2, 3, 4, 5, 1, 6, 2, 1, 7, 2]
    zpos = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

    # 生成测试数据(柱形参数)
    dx = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
    dy = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
    dz = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

    # 生成画布(两种形式)
    fig = plt.figure()
    ax = fig.gca(projection="3d", title="plot title")

    # 画三维柱状图
    ax.bar3d(xpos, ypos, zpos, dx, dy, dz, alpha=0.5)

    # 设置坐标轴图标
    ax.set_xlabel("X Label")
    ax.set_ylabel("Y Label")
    ax.set_zlabel("Z Label")

    # 图形显示
    plt.show()
    return
# three_dimension_bar()
```

##### 3.1 二维平面图画图时解释

###### （1）plt.axis([])

```python
plt.axis([0,6,0,20])
```

这句代码其实是让x轴从0-6，y轴从0-20.

###### (2) `text()`命令可用于在任意位置添加文本，

`xlabel()`，`ylabel()`和`title()`用于在指定的位置添加文本。

例如:

```python
import numpy as np
import matplotlib.pyplot as plt

mu, sigma = 100, 15
x = mu + sigma * np.random.randn(10000)

# 数据的直方图
n, bins, patches = plt.hist(x, 50, normed=1, facecolor='g', alpha=0.75)

plt.xlabel('Smarts')
plt.ylabel('Probability')
plt.title('Histogram of IQ')
plt.text(60, .025, r'$\mu=100,\ \sigma=15$')
plt.axis([40, 160, 0, 0.03])
plt.grid(True)
plt.show()
```

<img src="https://img-blog.csdnimg.cn/img_convert/cd8cb1f653306d6b40c1c2c57ab664d2.png" alt="img" style="zoom:50%;" />

 在python的matplotlib库中分别可用bar、barh、plot函数来构建它们，再使用xticks与yticks（设置坐标轴刻度）、xlabel与ylabel（设置坐标轴标签）、title（标题）、legend（图例）、xlim与ylim（设置坐标轴数据范围）、grid（设置网格线）等命令来装饰图形。

```python
import matplotlib.pyplot as plt
import numpy as np
#创建带数字标签的直方图
numbers = list(range(1,11))
#np.array()将列表转换为存储单一数据类型的多维数组
x = np.array(numbers)
y = np.array([a**2 for a in numbers])
plt.bar(x,y,width=0.5,align='center',color='c')
plt.title('Square Numbers',fontsize=24)
plt.xlabel('Value',fontsize=14)
plt.ylabel('Square of Value',fontsize=14)
plt.tick_params(axis='both',labelsize=14)
plt.axis([0,11,0,110])
for a,b in zip(x,y):
    plt.text(a,b+0.1,'%.0f'%b,ha = 'center',va = 'bottom',fontsize=7)
plt.savefig('images\squares.png')
plt.show()
```

首先，前边设置的x、y值其实就代表了不同柱子在图形中的位置（坐标），通过for循环找到每一个x、y值的相应坐标——a、b，再使用plt.text在对应位置添文字说明来生成相应的数字标签，而for循环也保证了每一个柱子都有标签。其中，a, b+0.05表示在每一柱子对应x值、y值上方0.05处标注文字说明，**'%.0f' % b,代表标注的文字，即每个柱子对应的y值，其中0表示不显示小数后面的数值，1就表示显示小数后面一位，以此类推**； ha='center', va= 'bottom'代表horizontalalignment（水平对齐）、verticalalignment（垂直对齐）的方式，fontsize则是文字大小。条形图、折线图也是如此设置，饼图则在pie命令中有数据标签的对应参数。对于累积柱状图、双轴柱状图则需要用两个for循环，同时通过a与b的不同加减来设置数据标签位置。

###### (3) 如果要将原有的坐标更换成其它的坐标显示

比如原来的x轴是0、1、2、3、4、5、6、7、8等，现在将0、1、2、3、4、5、6、7、8替换成工步1、工步2、工步3、工步4、工步5、工步6、工步7、工步8等。

利用的命令是xticks()

例如：xticks(x,label)，就是用label去替换x

```python
import numpy as np
import matplotlib.pyplot as plt
import calendar
x = range(1,13,1)
y = range(1,13,1)
plt.plot(x,y)
plt.xticks(x, calendar.month_name[1:13],color='blue',rotation=60)  #参数x空值X轴的间隔，第二个参数控制每个间隔显示的文本，后面两个参数控制标签的颜色和旋转角度
plt.show()
```

###### (4)  **关于maatplotlib中的legend()**

```python
ax.legend(ncol=6,bbox_to_anchor=(1.06, 1.14), loc=0, borderaxespad=0)
```

其中，ncol代表要将标签弄成几列（如果很多列会遮挡一部分图）；

**其中，**

```
bbox_to_anchor=(1.06, 1.14), loc=0, borderaxespad=0
```

是设置标签所处的位置，bbox_to_anchor=(1.06, 1.14)是将其放在图的什么位置，以图的原点为起点，（1，1）是右上角； loc=0, borderaxespad=0；

###### （5）**Python使用matplotlib绘图，如何在绘图结果上显示**

```python
import matplotlib.pyplot as plt  
import random
x1 = list(range(10))
y1 = [random.randint(0,10) for i in range(10)]  
plt.plot(x1, y1,  color='r',markerfacecolor='blue',marker='o')  
for a, b in zip(x1, y1):  
    plt.text(a, b, (a,b),ha='center', va='bottom', fontsize=10)  
 
plt.legend()  
plt.show()
```

<img src="https://img-blog.csdnimg.cn/img_convert/7089880c84d79893a74f09449354e9f8.png" alt="img" style="zoom:50%;" />



#### 4. 画3D图

 **一、初始化**

假设已经安装了matplotlib工具包。

利用matplotlib.figure.Figure创建一个图框：

```python
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure()
ax = fig.add_subplot(111, projection ='3d')`
```

![img](https://img-blog.csdnimg.cn/img_convert/f49ec03a4c589e87330df05f43c43485.png)

**二、直线绘制（Line plots）**

基本用法：

```python
ax.plot(x,y,z,label=' ')
```

code:

```python
import matplotlib as mpl
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import matplotlib.pyplot as plt

mpl.rcParams['legend.fontsize'] = 10

fig = plt.figure()
ax = fig.gca(projection='3d')
theta = np.linspace(-4 * np.pi, 4 * np.pi, 100)

z = np.linspace(-2, 2, 100)
r = z**2 + 1
x = r * np.sin(theta)
y = r * np.cos(theta)

ax.plot(x, y, z, label='parametric curve')
ax.legend()
plt.show()
```

![img](https://img-blog.csdnimg.cn/img_convert/71a086e88285e5a4011f06bc2d8b1a4a.png)

**三、散点绘制（Scatter plots）**

基本用法：

```python
ax.scatter(xs, ys, zs, s=20, c=None, depthshade=True, *args, *kwargs)
```

> - xs,ys,zs：输入数据；
> - s:scatter点的尺寸
> - c:颜色，如c = 'r'就是红色；
> - depthshase:透明化，True为透明，默认为True，False为不透明
> - *args等为扩展变量，如maker = 'o'，则scatter结果为’o‘的形状

```python
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import numpy as np

def randrange(n, vmin, vmax):
    '''
    Helper function to make an array of random numbers having shape (n, )
    with each number distributed Uniform(vmin, vmax).
    '''
    return (vmax - vmin)*np.random.rand(n) + vmin
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
n = 100

# For each set of style and range settings, plot n random points in the box
# defined by x in [23, 32], y in [0, 100], z in [zlow, zhigh].
for c, m, zlow, zhigh in [('r', 'o', -50, -25), ('b', '^', -30, -5)]:
    xs = randrange(n, 23, 32)
    ys = randrange(n, 0, 100)
    zs = randrange(n, zlow, zhigh)
    ax.scatter(xs, ys, zs, c=c, marker=m)

ax.set_xlabel('X Label')
ax.set_ylabel('Y Label')
ax.set_zlabel('Z Label')
plt.show()
```

![img](https://img-blog.csdnimg.cn/img_convert/649a240ae26050b9f660aae229a7c782.png)

**四、线框图（Wireframe plots）**

基本用法：

```python
ax.plot_wireframe(X, Y, Z, *args, **kwargs)
```

> - X,Y,Z：输入数据
> - rstride:行步长
> - cstride:列步长
> - rcount:行数上限
> - ccount:列数上限

code:

```python
from mpl_toolkits.mplot3d import axes3d
import matplotlib.pyplot as plt

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

# Grab some test data.
X, Y, Z = axes3d.get_test_data(0.05)

# Plot a basic wireframe.
ax.plot_wireframe(X, Y, Z, rstride=10, cstride=10)
plt.show()
```

![img](https://img-blog.csdnimg.cn/img_convert/0d0635aa94f7d5fd46a4f41a42ae9492.png)

**五、表面图（Surface plots）**

基本用法：

```python
ax.plot_surface(X, Y, Z, *args, **kwargs)
```

> - X,Y,Z：数据
> - rstride、cstride、rcount、ccount:同Wireframe plots定义
> - color:表面颜色
> - cmap:图层

code:

```python
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
from matplotlib import cm
from matplotlib.ticker import LinearLocator, FormatStrFormatter
import numpy as np

fig = plt.figure()
ax = fig.gca(projection='3d')

# Make data.
X = np.arange(-5, 5, 0.25)
Y = np.arange(-5, 5, 0.25)
X, Y = np.meshgrid(X, Y)
R = np.sqrt(X**2 + Y**2)
Z = np.sin(R)

# Plot the surface.
surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm, linewidth=0, antialiased=False)

# Customize the z axis.
ax.set_zlim(-1.01, 1.01)
ax.zaxis.set_major_locator(LinearLocator(10))
ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))

# Add a color bar which maps values to colors.
fig.colorbar(surf, shrink=0.5, aspect=5)
plt.show()
```

![img](https://img-blog.csdnimg.cn/img_convert/c10fb3c99fa24ba9990b92920e3ae228.png)

**六、三角表面图（Tri-Surface plots）**

基本用法：

```python
ax.plot_trisurf(*args, **kwargs)
```

> - X,Y,Z:数据
> - 其他参数类似surface-plot

code:

```python
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import numpy as np

n_radii = 8
n_angles = 36

# Make radii and angles spaces (radius r=0 omitted to eliminate duplication).
radii = np.linspace(0.125, 1.0, n_radii)
angles = np.linspace(0, 2*np.pi, n_angles, endpoint=False)

# Repeat all angles for each radius.
angles = np.repeat(angles[..., np.newaxis], n_radii, axis=1)

# Convert polar (radii, angles) coords to cartesian (x, y) coords.
# (0, 0) is manually added at this stage,  so there will be no duplicate
# points in the (x, y) plane.
x = np.append(0, (radii*np.cos(angles)).flatten())
y = np.append(0, (radii*np.sin(angles)).flatten())

# Compute z to make the pringle surface.
z = np.sin(-x*y)
fig = plt.figure()
ax = fig.gca(projection='3d')
ax.plot_trisurf(x, y, z, linewidth=0.2, antialiased=True)
plt.show()
```

![img](https://img-blog.csdnimg.cn/img_convert/9cdbbed865041816560479a604ec76b3.png)

**七、等高线（Contour plots）**

基本用法：

```python
ax.contour(X, Y, Z, *args, **kwargs)
```

code:

```python
from mpl_toolkits.mplot3d import axes3d
import matplotlib.pyplot as plt
from matplotlib import cm

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
X, Y, Z = axes3d.get_test_data(0.05)
cset = ax.contour(X, Y, Z, cmap=cm.coolwarm)
ax.clabel(cset, fontsize=9, inline=1)
plt.show()
```

![img](https://img-blog.csdnimg.cn/img_convert/94f1c58111585d5988b5a62f387112b2.png)

二维的等高线，同样可以配合三维表面图一起绘制：

code:

```python
from mpl_toolkits.mplot3d import axes3d
from mpl_toolkits.mplot3d import axes3d
import matplotlib.pyplot as plt
from matplotlib import cm

fig = plt.figure()

ax = fig.gca(projection='3d')
X, Y, Z = axes3d.get_test_data(0.05)
ax.plot_surface(X, Y, Z, rstride=8, cstride=8, alpha=0.3)
cset = ax.contour(X, Y, Z, zdir='z', offset=-100, cmap=cm.coolwarm)
cset = ax.contour(X, Y, Z, zdir='x', offset=-40, cmap=cm.coolwarm)
cset = ax.contour(X, Y, Z, zdir='y', offset=40, cmap=cm.coolwarm)

ax.set_xlabel('X')
ax.set_xlim(-40, 40)
ax.set_ylabel('Y')
ax.set_ylim(-40, 40)
ax.set_zlabel('Z')
ax.set_zlim(-100, 100)

plt.show()
```



![img](https://img-blog.csdnimg.cn/img_convert/12386476fef46237794b3d21e5214d71.png)

也可以是三维等高线在二维平面的投影：

code:

```python
from mpl_toolkits.mplot3d import axes3d
import matplotlib.pyplot as plt
from matplotlib import cm

fig = plt.figure()
ax = fig.gca(projection='3d')
X, Y, Z = axes3d.get_test_data(0.05)
ax.plot_surface(X, Y, Z, rstride=8, cstride=8, alpha=0.3)
cset = ax.contourf(X, Y, Z, zdir='z', offset=-100, cmap=cm.coolwarm)
cset = ax.contourf(X, Y, Z, zdir='x', offset=-40, cmap=cm.coolwarm)
cset = ax.contourf(X, Y, Z, zdir='y', offset=40, cmap=cm.coolwarm)

ax.set_xlabel('X')
ax.set_xlim(-40, 40)
ax.set_ylabel('Y')
ax.set_ylim(-40, 40)
ax.set_zlabel('Z')
ax.set_zlim(-100, 100)
plt.show()
```

![img](https://img-blog.csdnimg.cn/img_convert/5dec7cc1a5f85d60b365f156a93c25d0.png)

 **八、Bar plots（条形图）**

基本用法：

```
ax.bar(left, height, zs=0, zdir='z', *args, **kwargs
```

> - x，y，zs = z，数据
> - zdir:条形图平面化的方向，具体可以对应代码理解。

code:

```python
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import numpy as np

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
for c, z in zip(['r', 'g', 'b', 'y'], [30, 20, 10, 0]):
    xs = np.arange(20)
    ys = np.random.rand(20)
    # You can provide either a single color or an array. To demonstrate this,
    # the first bar of each set will be colored cyan.
    cs = [c] * len(xs)
    cs[0] = 'c'
    ax.bar(xs, ys, zs=z, zdir='y', color=cs, alpha=0.8)
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()
```

![img](https://img-blog.csdnimg.cn/img_convert/5f9ceaa8cacd5bbd293c3c3a8e1e4cf8.png)

**九、子图绘制（subplot）**

　　**A-不同的2-D图形，分布在3-D空间**，其实就是投影空间不空，对应code:

```python
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import matplotlib.pyplot as plt

fig = plt.figure()
ax = fig.gca(projection='3d')
# Plot a sin curve using the x and y axes.
x = np.linspace(0, 1, 100)
y = np.sin(x * 2 * np.pi) / 2 + 0.5
ax.plot(x, y, zs=0, zdir='z', label='curve in (x,y)')
# Plot scatterplot data (20 2D points per colour) on the x and z axes.
colors = ('r', 'g', 'b', 'k')
x = np.random.sample(20*len(colors))
y = np.random.sample(20*len(colors))
c_list = []
for c in colors:
    c_list.append([c]*20)
# By using zdir='y', the y value of these points is fixed to the zs value 0
# and the (x,y) points are plotted on the x and z axes.
ax.scatter(x, y, zs=0, zdir='y', c=c_list, label='points in (x,z)')
# Make legend, set axes limits and labels

ax.legend()
ax.set_xlim(0, 1)
ax.set_ylim(0, 1)
ax.set_zlim(0, 1)
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
```

![img](https://img-blog.csdnimg.cn/img_convert/a7478d29471638cb406afead3fcdd329.png)

 　**B-子图Subplot用法**

与MATLAB不同的是，如果一个四子图效果，如：

![img](https://img-blog.csdnimg.cn/img_convert/5e5465a5cd2df727e4821db76052d78b.png)

![image-20221026174625152](C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221026174625152.png)

code:

```python
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d.axes3d import Axes3D, get_test_data
from matplotlib import cm
import numpy as np

# set up a figure twice as wide as it is tall
fig = plt.figure(figsize=plt.figaspect(0.5))

#===============
#  First subplot
#===============
# set up the axes for the first plot
ax = fig.add_subplot(2, 2, 1, projection='3d')

# plot a 3D surface like in the example mplot3d/surface3d_demo
X = np.arange(-5, 5, 0.25)
Y = np.arange(-5, 5, 0.25)

X, Y = np.meshgrid(X, Y)
R = np.sqrt(X**2 + Y**2)
Z = np.sin(R)
surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm,linewidth=0, antialiased=False)
ax.set_zlim(-1.01, 1.01)
fig.colorbar(surf, shrink=0.5, aspect=10)
#===============
# Second subplot
#===============
# set up the axes for the second plot
ax = fig.add_subplot(2,1,2, projection='3d')
# plot a 3D wireframe like in the example mplot3d/wire3d_demo
X, Y, Z = get_test_data(0.05)
ax.plot_wireframe(X, Y, Z, rstride=10, cstride=10)
plt.show()
```

![img](https://img-blog.csdnimg.cn/img_convert/c601c6f92bccff6f4e087e04051c2737.png)

 **补充：**

文本注释的基本用法：

code:

```python
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

fig = plt.figure()
ax = fig.gca(projection='3d')
# Demo 1: zdir
zdirs = (None, 'x', 'y', 'z', (1, 1, 0), (1, 1, 1))
xs = (1, 4, 4, 9, 4, 1)
ys = (2, 5, 8, 10, 1, 2)
zs = (10, 3, 8, 9, 1, 8)

for zdir, x, y, z in zip(zdirs, xs, ys, zs):
    label = '(%d, %d, %d), dir=%s' % (x, y, z, zdir)
    ax.text(x, y, z, label, zdir)
# Demo 2: color
ax.text(9, 0, 0, "red", color='red')

# Demo 3: text2D
# Placement 0, 0 would be the bottom left, 1, 1 would be the top right.
ax.text2D(0.05, 0.95, "2D Text", transform=ax.transAxes)

# Tweaking display region and labels
ax.set_xlim(0, 10)
ax.set_ylim(0, 10)
ax.set_zlim(0, 10)
ax.set_xlabel('X axis')
ax.set_ylabel('Y axis')
ax.set_zlabel('Z axis')
plt.show()
```

![img](https://img-blog.csdnimg.cn/img_convert/076224422508912fc21e26a1ebc87e16.png)

### （7）zip函数

python中zip()函数用法举例

 定义：zip([iterable, ...])
　　**zip()是Python的一个内建函数，它接受一系列可迭代的对象作为参数，将对象中对应的元素打包成一个个tuple（元组）**，然后返回由这些tuples组成的list（列表）。若传入参数的长度不等，则返回list的长度和参数中长度最短的对象相同。利用*号操作符，可以将list unzip（解压），看下面的例子就明白了：

```python
a = [1, 2, 3]
b = [2, 3, 4]
c = [4, 5, 6, 7]
# 返回一个对象
zipped = zip(a, b)
 
# list() 转换为列表
print(list(zipped))
运行结果：
[(1, 2), (2, 3), (3, 4)]
 
# 元素个数与最短的列表一致
zipped = zip(a, c)
print(list(zipped))
print(type(zipped), zipped)
运行结果：
[(1, 4), (2, 5), (3, 6)]
<class 'zip'> <zip object at 0x000001C7C9814180>
 
# 对zip对象进行解压缩
a1, a2 = zip(*zip(a, c))
print(a1, a2)
运行结果：
(1, 2, 3) (4, 5, 6)
 
# zip对象可以转化为字典
name_list = ["bob", "jim", "james", "julie", "june"]
number_list = ["1", "2", "3", "4", "5"]
name_and_number = dict(zip(name_list, number_list))
print(name_and_number)
运行结果：
{'bob': '1', 'jim': '2', 'james': '3', 'julie': '4', 'june': '5'}
 
# 搭配for循环，支持并行迭代操作方法   zip()方法用在for循环中，就会支持并行迭代：
l1 = [2, 3, 4]
l2 = [4, 5, 6]
for (x, y) in zip(l1, l2):
    print(x, y, '--', x * y)
运行结果：
2 4 -- 8
3 5 -- 15
4 6 -- 24
 
其实它的工作原理就是使用了zip()的结果，在for循环里解包zip结果中的元组，用元组赋值运算。
就好像(x,y)=(2,6)，赋值、序列解包操作。在对文件的操作中我们也会用到遍历，
例如Python遍历文件夹目录与文件操作，就是很方便实用的。
 
# 二维矩阵变换（矩阵的行列互换）
a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
# 方法一，推导式：
print([[row[col] for row in a] for col in range(len(a[0]))])
运行结果：
[[1, 4, 7], [2, 5, 8], [3, 6, 9]]
 
# 方法二，利用zip函数：
print(list(zip(*a)))
print(list(map(list, zip(*a))))
运行结果：
[(1, 4, 7), (2, 5, 8), (3, 6, 9)]
[[1, 4, 7], [2, 5, 8], [3, 6, 9]]
 
这种方法速度更快但也更难以理解，将list看成tuple解压，恰好得到我们“行列互换”的效果，
再通过对每个元素应用list()函数，将tuple转换为list
```

### （8）关于Python中if __name__ == ‘__main__‘：的作用和原理

if __name__ == '__main__':的作用

一个python文件通常有两种使用方法，第一是作为脚本直接执行，第二是 import 到其他的 python 脚本中被调用（模块重用）执行。因此 if __name__ == 'main': 的作用就是控制这两种情况执行代码的过程，在 if __name__ == 'main': 下的代码只有在第一种情况下（即文件作为脚本直接执行）才会被执行，而 import 到其他脚本中是不会被执行的。举例说明如下：

直接执行

![img](https://img-blog.csdnimg.cn/20190510141202522.png)


直接执行 test.py，结果如下图，可以成功 print 两行字符串。即，if __name__=="__main__": 语句之前和之后的代码都被执行。

![img](https://img-blog.csdnimg.cn/20190510141303114.png)

import 执行
然后在同一文件夹新建名称为 import_test.py 的脚本，输入如下代码：

![img](https://img-blog.csdnimg.cn/20190510141602268.png)

执行 import_test.py 脚本，输出结果如下：

![img](https://img-blog.csdnimg.cn/20190510141624918.png)

只输出了第一行字符串。即，if __name__=="__main__": 之前的语句被执行，之后的没有被执行。

if __name__ == '__main__':的运行原理

每个python模块（python文件，也就是此处的 test.py 和 import_test.py）都包含内置的变量 __name__，当该模块被直接执行的时候，__name__ 等于文件名（包含后缀 .py ）；如果该模块 import 到其他模块中，则该模块的 __name__ 等于模块名称（不包含后缀.py）。

而 “__main__” 始终指当前执行模块的名称（包含后缀.py）。进而当模块被直接执行时，__name__ == 'main' 结果为真。

为了进一步说明，我们在 test.py 脚本的 if __name__=="__main__": 之前加入 print(__name__)，即将 __name__ 打印出来。文件内容和结果如下：

![img](https://img-blog.csdnimg.cn/20190510142230219.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hlcWlhbmc1MjU=,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/20190510142253482.png)

可以看出，此时变量__name__的值为"__main__"。

再执行 import_test.py，执行结果如下：

![img](https://img-blog.csdnimg.cn/20190510142441889.png)

![img](https://img-blog.csdnimg.cn/20190510142452571.png)

此时，**test.py中的__name__变量值为 test，**不满足 __name__=="__main__" 的条件，因此，无法执行其后的代码。

### （9）关于二维数组画图的时候（牵扯到故障诊断实验时画图）

![image-20221028195618921](C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221028195618921.png)

### （10）关于.npy文件

***在使用训练好的模型时，其中有一种保存的模型文件格式叫.npy。***

##### 1. 关于.npy文件的读取与保存

```python
import numpy as np
arr = np.array([[1, 2, 3]
				[4, 5, 6]])
# .npy的保存
np.save('weight.npy', arr)
# .npy的读取
LoadData = np.load('weight.npy')
```

##### 2. 关于.npy在深度神经网络中作为权重的实战案例

在深度神经网络训练过程中通常需要读取预训练权重，预训练权重通常是 .npy文件，比如vgg16.npy（https://pan.baidu.com/s/18O3lZ2Zk0pkxBllK9XF-IQ   提取码：5spy）。本次就以分析vgg16.npy为例进行说明。

```python
import numpy as np
# 注意编码方式
pre_train = np.load("vgg16.npy", allow_pickle=True, encoding="latin1")

print("------type-------")
print(type(pre_train))
print("------shape-------")
print(pre_train.shape)
print("------data-------")
print(pre_train)
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190529181141706.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzMjU0ODcw,size_16,color_FFFFFF,t_70)

这是个啥？为啥shape没有？ 但是可以看出来 pre_train 里元素应该是一个字典，我们尝试取出来。
注：ndarray.item()是复制数组中的一个元素，并将其返回。具体语法参见：https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.item.html?highlight=item#numpy.ndarray.item

```python
import numpy as np

pre_train = np.load("vgg16.npy", allow_pickle=True, encoding="latin1")

data_dic = pre_train.item()

print("------type-------")
print(type(data_dic))
print("------conv1_1  data-------")
print(data_dic['conv1_1'])   # 返回一个列表，该列表有两个array，表示conv1_1的权重w与偏置b
print("------conv1_1  shape-------")
print((data_dic['conv1_1'][0]).shape)
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190529181910255.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190529181927991.png)

可以发现，这是第一个卷积层的权重参数，输入channel是3，输出channel是64。

### （11）Python中的range函数和arange函数的区别与联系

#####            **1.range()函数和arange()函数最大的区别**

前者是Python内置的函数，直接调用即可；后者是numpy中的函数，调用时一般采用np.arange()。

```python
import numpy as np 
 
for i in np.arange(10):
    print(i)
```

#####         **2.range()函数仅支持整数步长**

我们知道，range()函数具有3个参数，分别是起点、终点和步长。需要注意的是这3个参数均为整数型，不能设置为浮点型，这也导致了range()函数的返回值同样都是整数型的。

```python
# range()函数的三种使用方法
 
# 1.仅设置终点参数，默认起点为0，步长为1，返回值范围为[起点，终点)
>>>range(10)
0,1,2,3,4,5,6,7,8,9
 
# 2.设置起点和终点，步长默认为1，返回值范围为[起点，终点)
>>>range(2,10)
2,3,4,5,6,7,8,9
 
# 3.设置起点、终点和步长
>>>range(1,10,2)
1,3,5,7,9
 
# 当设置起点、终点或步长为小数时，将会报错
>>>range(1,10,2.1)
TypeError: 'float' object cannot be interpreted as an integer
```

#####        **3.np.arange()函数支持小数步长**

当然，在项目开过程中难免会遇到需要小数迭代序列，这时就需要np.arange()函数发挥它的作用了！首先，需要明确range()函数对整数参数的使用，np.arange()函数都能替代。

```crystal
# np.arange()函数的整数型参数设置
 
# 1.仅设置终点参数，默认起点为0，步长为1，返回值范围为[起点，终点)
>>>np.arange(10)
0,1,2,3,4,5,6,7,8,9
 
# 2.设置起点和终点，步长默认为1，返回值范围为[起点，终点)
>>>np.arange(2,10)
2,3,4,5,6,7,8,9
 
# 3.设置起点、终点和步长
>>>np.arange(1,10,2)
1,3,5,7,9
```

其次，np.arange()函数的3个参数均可设置为小数，可以最大自由化我们的需求。

```python
# np.arange()函数的整数型参数设置
 
# 1.终点为小数，默认起点为0.0，步长为1.0
>>>np.arange(10.2)
0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0
 
# 2.设置起点和终点均为小数，步长默认为1.0，返回值范围为[起点，终点)
>>>np.arange(2.1, 5.1)
2.1,3.1,4.1
 
# 3.设置起点、终点和步长均为小数
>>>np.arange(1.1, 5.2, 1.1)
1.1,2.2,3.3,4.4
```

#####   **4. 两者数据类型不同**

range()函数返回的类型为range对象，np.arange()函数返回的类型为array类型对象。作者认为该区别影响不大，不做过多赘述。

### （12） np.array()和np.asarray()的区别

**一句话概括**：

是否copy：主要区别在于 np.array （默认情况下）将会copy该对象，而 np.asarray 除非必要，否则不会copy该对象。

和array功能相关：y_train = np.asarray(train_labels).astype('float32')

```python
import numpy as np
 
#example 1:
data1=[[1,1,1],[1,1,1],[1,1,1]]
arr2=np.array(data1)
arr3=np.asarray(data1)
data1[1][1]=2
print 'data1:\n',data1
print 'arr2:\n',arr2
print 'arr3:\n',arr3

# 输出：可见array和asarray没有区别，都对元数据进行了复制。
data1:
[[1, 1, 1], [1, 2, 1], [1, 1, 1]]
arr2:
[[1 1 1]
 [1 1 1]
 [1 1 1]]
arr3:
[[1 1 1]
 [1 1 1]
 [1 1 1]]

import numpy as np
 
#example 2:
arr1=np.ones((3,3))
arr2=np.array(arr1)
arr3=np.asarray(arr1)
arr1[1]=2
print 'arr1:\n',arr1
print 'arr2:\n',arr2
print 'arr3:\n',arr3

# 输出：此时两者才表现出区别。修改了arr1，arr3也会跟着修改。
arr1:
[[ 1.  1.  1.]
 [ 2.  2.  2.]
 [ 1.  1.  1.]]
arr2:
[[ 1.  1.  1.]
 [ 1.  1.  1.]
 [ 1.  1.  1.]]
arr3:
[[ 1.  1.  1.]
 [ 2.  2.  2.]
 [ 1.  1.  1.]]
```

### （13）Python的reshape的用法：reshape(1,-1)

##### 1. numpy.arange(n).reshape(a, b)   依次生成n个自然数，并且以a行b列的数组形式显示

```python
np.arange(16).reshape(2,8) #生成16个自然数，以2行8列的形式显示
# Out: 
# array([[ 0,  1,  2,  3,  4,  5,  6,  7],
#       [ 8,  9, 10, 11, 12, 13, 14, 15]])
```

##### 2. mat (or array).reshape(c, -1)   必须是**矩阵格式或者数组格式**，才能使用 .reshape(c, -1) 函数， 表示将此矩阵或者数组重组，以 c行d列的形式表示

```python
arr.shape    # (a,b)
arr.reshape(m,-1) #改变维度为m行、d列 （-1表示列数自动计算，d= a*b /m ）
arr.reshape(-1,m) #改变维度为d行、m列 （-1表示行数自动计算，d= a*b /m ）
```

-1的作用就在此**: 自动计算d：d=数组或者矩阵里面所有的元素个数/c**, d必须是整数，不然报错）（[reshape](https://so.csdn.net/so/search?q=reshape&spm=1001.2101.3001.7020)(-1, m)即列数固定，行数需要计算）

```python
arr=np.arange(16).reshape(2,8)
arr
'''
out:
array([[ 0,  1,  2,  3,  4,  5,  6,  7],
       [ 8,  9, 10, 11, 12, 13, 14, 15]])
'''
 
arr.reshape(4,-1) #将arr变成4行的格式，列数自动计算的(c=4, d=16/4=4)
'''
out:
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11],
       [12, 13, 14, 15]])
''' 
arr.reshape(8,-1) #将arr变成8行的格式，列数自动计算的(c=8, d=16/8=2)
'''
out:
array([[ 0,  1],
       [ 2,  3],
       [ 4,  5],
       [ 6,  7],
       [ 8,  9],
       [10, 11],
       [12, 13],
       [14, 15]])
''' 
arr.reshape(10,-1) #将arr变成10行的格式，列数自动计算的(c=10, d=16/10=1.6 != Int)
'''
out:
ValueError: cannot reshape array of size 16 into shape (10,newaxis)
'''
```

### （14）Dense层

首先，什么是Dense呢？它是一个全连接的网络层，就目前的水平而言，你把Dense当做一个黑盒就行，它的参数比较多，目前我们只用到了两个，用于定义输入输出的格式，第一个是输出的维度，第二个是输入的维度。

举两个例子
Dense(1,input_dim = 1))
定义了一个输入一维，输出也是一维的网络
Dense(2, input_dim=2)
定义了一个输入二维，输出也是二维的网络

如果我们想计算两个数的加法，应该怎么传参数呢？加法是把输入的两个数（加数和被加数),变成一个数(和),所以，输入是二维，输出是一维，定义如下
Dense(1, input_dim=2)

```python
from keras.models import Sequential  
from keras.layers import Dense
import numpy as np
import random
def generateData():
    i = 1
    X =[]
    Y = []
    while i < 1000:
        t1 = random.randint(0,1000)
        t2 = random.randint(0,1000)
        X.append([t1, t2])
        Y.append( t1 + t2)
        i = i + 1
    return np.array( X), np.array(Y)

model = Sequential()
model.add(Dense(1,input_dim = 2))
model.compile(loss='mean_absolute_error', optimizer ='adam')
model.summary()

X,Y=generateData()

model.fit(X[0:700],Y[0:700], epochs=500, batch_size=1)

scores= model.evaluate(x=X[70:],y=Y[70:])

print(scores)

t = np.array([[2020,4040]])
print(model.predict(t))
```



### （15）**model.compile()方法用于在配置训练方法时，告知训练时用的优化器、损失函数和准确率评测标准**

> model.compile(optimizer = 优化器， loss = 损失函数， metrics = ["准确率”])
>
> 其中：
>
> **optimizer可以是字符串形式给出的优化器名字，也可以是函数形式，使用函数形式可以设置学习率、动量和超参数**
>
> ​				例如：“sgd”   或者   tf.optimizers.SGD(lr = 学习率，decay = 学习率衰减率， momentum = 动量参数）
>
> ​		 	“adagrad"  或者  tf.keras.optimizers.Adagrad(lr = 学习率，decay = 学习率衰减率）
>
> ​				”adadelta"  或者  tf.keras.optimizers.Adadelta(lr = 学习率，decay = 学习率衰减率）
>
> ​				“adam"  或者  tf.keras.optimizers.Adam(lr = 学习率， decay = 学习率衰减率）
>
> **loss可以是字符串形式给出的损失函数的名字，也可以是函数形式**
>
> ​			例如：”mse" 或者 tf.keras.losses.MeanSquaredError()
>
> ​			"sparse_categorical_crossentropy"  或者  tf.keras.losses.SparseCatagoricalCrossentropy(from_logits = False)
>
> ​			损失函数经常需要使用softmax函数来将输出转化为概率分布的形式，在这里from_logits代表是否将输出转为概率分布的形式，为False时表示转换为概率分布，为True时表示不转换，直接输出
>
> **Metrics标注网络评价指标**
>
> ​		例如：
>
> ​			"accuracy" : y_ 和 y 都是数值，如y_ = [1] y = [1]  #y_为真实值，y为预测值
>
> ​			“sparse_accuracy":y_和y都是以独热码 和概率分布表示，如y_ = [0, 1, 0], y = [0.256, 0.695, 0.048]
>
> ​			"sparse_categorical_accuracy" :y_是以数值形式给出，y是以 独热码给出，如y_ = [1], y = [0.256 0.695, 0.048]

```python
#第一步，import
import tensorflow as tf #导入模块
from sklearn import datasets #从sklearn中导入数据集
import numpy as np #导入科学计算模块
import keras
 
#第二步，train, test
x_train = datasets.load_iris().data #导入iris数据集的输入
 
y_train = datasets.load_iris().target #导入iris数据集的标签
 
np.random.seed(120) #设置随机种子，让每次结果都一样，方便对照
 
np.random.shuffle(x_train) #使用shuffle()方法，让输入x_train乱序
 
np.random.seed(120) #设置随机种子，让每次结果都一样，方便对照
 
np.random.shuffle(y_train) #使用shuffle()方法，让输入y_train乱序
 
tf.random.set_seed(120) #让tensorflow中的种子数设置为120
 
#第三步，models.Sequential()
model = tf.keras.models.Sequential([ #使用models.Sequential()来搭建神经网络
    tf.keras.layers.Dense(3, activation = "softmax", kernel_regularizer = tf.keras.regularizers.l2()) #全连接层，三个神经元，激活函数为softmax,使用l2正则化
])
 
#第四步，model.compile()
model.compile(  #使用model.compile()方法来配置训练方法
    optimizer = tf.keras.optimizers.SGD(lr = 0.1), #使用SGD优化器，学习率为0.1
    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), #配置损失函数
    metrics = ['sparse_categorical_accuracy'] #标注网络评价指标
)
 
#第五步，model.fit()
model.fit(  #使用model.fit()方法来执行训练过程，
    x_train, y_train, #告知训练集的输入以及标签，
    batch_size = 32, #每一批batch的大小为32，
    epochs = 500, #迭代次数epochs为500
    validation_split = 0.2, #从测试集中划分80%给训练集
    validation_freq = 20 #测试的间隔次数为20
)
 
#第六步，model.summary()
model.summary() #打印神经网络结构，统计参数数目
```

### （16）如果想要以断点和jupyter那样debug和输出的时候，在想要断点的地方加from IPython import emdeb; embde()



 

## 1.2 Python库函数

### （1）PrettyTable介绍与基本使用

相信很多小伙伴在使用`python`需要查看表格数据，直接`print`出来呢？又乱了。`PrettyTable`可以解决这个问题，说个简单的应用，在爬`12306`网站的数据，需要表格展示，更加清晰，如下图：
![在这里插入图片描述](https://img-blog.csdnimg.cn/9b354cf2c69b47f78507a82c025e6222.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAY3VudG91MDkwNg==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)
   这样在输出的窗口可以很清晰看到所需要的信息。那么类似这种表格要怎么做出来呢？没错，使用`PrettyTable`就会把事情变得很简单。

#### PrettyTable 安装

   `PrettyTable `安装很简单，直接使用`pip`安装即可：

```python
python -m pip install -U prettytable
####      或者
pip install -U prettytable
123
```

#### PrettyTable 基本使用

   `PrettyTable`用于创建和展示表格数据，所以就先创建个表格把。

**创建表格**

```python
from prettytable import PrettyTable
x = PrettyTable()
12
```

   当然我们可以设置表格的名称：

```python
x.title = 'Table 1  City Info'
1
```

**添加一行数据**

   接下来给表格添加数据，包括字段名和数据，分别用`field_name`s和`add_row`函数，例子来自官网：

```python
x.field_names = ["City name", "Area", "Population", "Annual Rainfall"]
x.add_row(["Adelaide", 1295, 1158259, 600.5])
x.add_row(["Brisbane", 5905, 1857594, 1146.4])
x.add_row(["Darwin", 112, 120900, 1714.7])
x.add_row(["Hobart", 1357, 205556, 619.5])
x.add_row(["Sydney", 2058, 4336374, 1214.8])
x.add_row(["Melbourne", 1566, 3806092, 646.9])
x.add_row(["Perth", 5386, 1554769, 869.4])
12345678
```

   现在就打印出来看看，直接`print(x)`。
![在这里插入图片描述](https://img-blog.csdnimg.cn/3fcf0100561a4bf3a16ec81af4232227.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAY3VudG91MDkwNg==,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center)
   这种可视化的效果真的好。那接下来在看看其他的方法。

**一次性添加多行**

```python
x.field_names = ["City name", "Area", "Population", "Annual Rainfall"]
x.add_rows(
    [
        ["Adelaide", 1295, 1158259, 600.5],
        ["Brisbane", 5905, 1857594, 1146.4],
        ["Darwin", 112, 120900, 1714.7],
        ["Hobart", 1357, 205556, 619.5],
        ["Sydney", 2058, 4336374, 1214.8],
        ["Melbourne", 1566, 3806092, 646.9],
        ["Perth", 5386, 1554769, 869.4],
    ]
)
123456789101112
```

**添加一列**

```python
x.add_column("City name",
["Adelaide","Brisbane","Darwin","Hobart","Sydney","Melbourne","Perth"])
x.add_column("Area", [1295, 5905, 112, 1357, 2058, 1566, 5386])
x.add_column("Population", [1158259, 1857594, 120900, 205556, 4336374, 3806092,
1554769])
x.add_column("Annual Rainfall",[600.5, 1146.4, 1714.7, 619.5, 1214.8, 646.9,
869.4])
1234567
```

   注意：add_column的第一个参数表示列的字段名，为字符串，第二个参数为列表，即添加到该列的数据。没有一次性添加多列的方法。
  当然，可以混合使用`add_row`和`add_column`，但是混合使用很容易混乱。

**根据csv导入**
   `prettytable`支持从`csv`文件中导入数据并创建表格，需要注意的是，字符串需要加上引号。

```python
from prettytable import from_csv
with open("CityInfo.csv") as fp:
    mytable = from_csv(fp)
print(mytable)
1234
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/ee28b47779054471b16f91443c70d6e2.png#pic_center)![在这里插入图片描述](https://img-blog.csdnimg.cn/1a57f74e14884f3cb82f67510148919d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAY3VudG91MDkwNg==,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center)
**从数据库中导入**

```python
import sqlite3
from prettytable import from_db_cursor

connection = sqlite3.connect("mydb.db")
cursor = connection.cursor()
cursor.execute("SELECT field1, field2, field3 FROM my_table")
mytable = from_db_cursor(cursor)
1234567
```

**表数据的删除**

   `prettytable`提供四种方法用于删除数据：

- `del_row`：删除某行，允许传入一个整数参数，（从0开始）。
- `del_column`：删除某列，允许传入一个字符串，表示要删除的列的字段名。
- `clear_rows`：删除所有数据，但保存列的字段名。
- `clear`：删除所有数据，包括列的字段名。

**显示表格**
   前面弄了那么多，都是为了最后的表格显示，这里说说`prettytable`的显示表格方法。最简单的就是：

```python
print(x)
1
mystring = x.get_string()
1
```

   `get_string()`函数可以将上面`print`的结果直接转化为字符串，可以将这个结果写到文本文件里。当然也可以打印出来。

```python
print(x.get_string())
1
```

**显示指定的列**

```python
print(x.get_string(fields=["City name", "Population"]))
1
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/cb8ccf09e6754f1081bab73f8e6ff797.png#pic_center)

**显示指定的行**

```python
print(x.get_string(start=1, end=4))
1
```

  这里的`start`和`end`分别表示所要显示的起始行和终止行。这里的索引和`python`一样，从`0`开始，并且不包括`end`所指的行。
![在这里插入图片描述](https://img-blog.csdnimg.cn/ad0c566caf0b4081beb63a2d4de32aa9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAY3VudG91MDkwNg==,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center)二、机器学习与深度学习相关知识

### （2）用scipy库中的io.loadmat读取.mat文件

```
from scipy import io
data = io.loadmat(os.path.join(folder, domain + ‘’))
```

### （3）cvxopt库

```
1. 创建矩阵

2. 求解线性规划
from cvxopt import matrix, solvers
A = matrix([ [-1.0, -1.0, 0.0, 1.0], [1.0, -1.0, -1.0, -2.0] ])
b = matrix([ 1.0, -2.0, 0.0, 4.0 ])
c = matrix([ 2.0, 1.0 ])
sol=solvers.lp(c,A,b)
pcost dcost gap pres   dres   k/t
0:  2.6471e+00 -7.0588e-01  2e+01  8e-01  2e+00  1e+00
1:  3.0726e+00  2.8437e+00  1e+00  1e-01  2e-01  3e-01
2:  2.4891e+00  2.4808e+00  1e-01  1e-02  2e-02  5e-02
3:  2.4999e+00  2.4998e+00  1e-03  1e-04  2e-04  5e-04
4:  2.5000e+00  2.5000e+00  1e-05  1e-06  2e-06  5e-06
5:  2.5000e+00  2.5000e+00  1e-07  1e-08  2e-08  5e-08
>>> print(sol['x'])
[ 5.00e-01]
[ 1.50e+00]
```

### （4）pylustrator

只需要导入pylustrator，开启pylustrator即可，添加两行代码：

```text
# 导入pylustrator 
import pylustrator 

# 开启pylustrator 
pylustrator.start()
```

举个例子，

```text
import numpy as np
import matplotlib.pyplot as plt 

import pylustrator  
pylustrator.start() #开启pylustrator


def f(t):
    return np.exp(-t) * np.cos(2 * np.pi * t)


t1 = np.arange(0.0, 5.0, 0.1)
t2 = np.arange(0.0, 5.0, 0.02)

plt.style.use('ggplot')
plt.subplot(211)
plt.plot(t1, f(t1), color='tab:blue', marker='o')
plt.plot(t2, f(t2), color='black')

plt.subplot(212)
plt.plot(t2, np.cos(2 * np.pi * t2), color='tab:orange', linestyle='--')
plt.show()
```

## 1.3 项目玩耍

### 1.3.1  爬虫

#### （1）关于requests设置请求头headers

> import requests
>
> url = 'xxxxx'; # 网页链接
>
> headers = {
>
> } # 里面是解决反爬虫问题



# 二、 机器学习与深度学习相关知识

## （1）欠采样和过采样

过采样和欠采样是处理非平衡分类问题时的常用手段。

拿二元分类为例，如果训练集中阳性样本有1000个，阴性样本有10万个，两者比例为1：100严重失衡。为了一些模型的性能考虑，我们需要进行一些处理使得两者的比例尽可能接近。

过采样：对少的一类进行重复选择，比如我们对1000个阳性样本进行有放回的抽样，抽5万次（当然其中有很多重复的样本），现在两类的比例就变成了1：2，比较平衡。

欠采样：对多的一类进行少量随机选择，比如我们对10万个阴性样本进行随机选择，抽中2000个（当然原样本中很多样本未被选中），现在两类的比例就变成了1：2，比较平衡。

SMOTE：SMOTE算法的基本思想就是对少数类别样本进行分析和模拟，并将人工模拟的新样本添加到数据集中，进而使原始数据中的类别不再严重失衡。该算法的模拟过程采用了KNN技术。

## （2）经验风险最小化与结构风险最小化

#### 经验风险最小化

经验风险最小化的策略认为，经验风险最小的模型是最优的模型：

![[公式]](https://www.zhihu.com/equation?tex=+%5Cmin_%7Bf%5Cin+F%7D%5Cfrac%7B1%7D%7BN%7D%5Csum%5EN_%7Bi%3D1%7DL%28y_i%2Cf%28x_i%29%29%5Ctag7+%5C%5C)

当样本**容量足够大**时，经验风险最小化能保证有很好的学习效果。比如，**极大似然估计**就是经验风险最小化的一个例子，`当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计`。

但当样本容量很小时，经验风险最小化容易导致“过拟合”。

#### 结构风险最小化

结构风险最小化（structural minimization, SRM）是为了防止过拟合提出的策略。结构风险最小化等价于正则化（regularization）。结构风险在经验风险上加上表示模型复杂度的**正则化项**（regularizer）或**罚项**（penalty term）。结构风险的定义是：

![[公式]](https://www.zhihu.com/equation?tex=+R_%7Bsrm%7D%28f%29%3D%5Cfrac%7B1%7D%7BN%7D%5Csum%5E%7BN%7D_%7Bi%3D1%7DL%28y_i%2Cf%28x_i%29%29%2B%5Clambda+J%28f%29+%5Ctag8+%5C%5C)

其中![[公式]](https://www.zhihu.com/equation?tex=J%28f%29)是模型复杂度的函数，![[公式]](https://www.zhihu.com/equation?tex=%5Clambda%5Cgeq0)是系数，用来权衡经验风险和模型复杂度。

结构风险最小化的策略认为结构风险最小的模型是最优模型：

![[公式]](https://www.zhihu.com/equation?tex=+%5Cmin_%7Bf%5Cin+F%7D%5B%5Cfrac%7B1%7D%7BN%7D%5Csum%5EN_%7Bi%3D1%7DL%28y_i%2Cf%28x_i%29%29%2B%5Clambda+J%28f%29%5D+%5C%5C)

结构风险小`需要经验风险和模型复杂度同时都小`，结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。

比如，贝叶斯估计中的最大后验概率估计（maximum posterior probability estimation,MAP）就是结构风险最小化的一个例子，`当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时`，结构风险最小化就等价于最大后验概率估计。

## **（3）最小二乘法的几何意义**

![image-20220913185923965](C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220913185923965.png)

## （4）极大似然估计

极大似然估计是求取似然函数的概率最大时的参数值

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220915212017806.png" alt="image-20220915212017806" style="zoom:50%;" />

##  (5) **Python sklearn机器学习的分类和回归评价指标——Sklearn.metrics简介及应用示例**

 无论利用机器学习算法进行回归、分类或者聚类时，**评价指标**，即检验机器学习模型效果的定量指标，都是一个不可避免且十分重要的问题。

例如：

```python
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
```

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)调用方式为：直接使用函数名调用，计算均方误差mean squared error

mse = mean_squared_error(y_test, y_pre)

 计算回归的决定系数R2：

R2 = r2_score(y_test,y_pre)

**回归指标**

```python
explained_variance_score(y_true, y_pred, sample_weight=None, multioutput=‘uniform_average’)：回归方差(反应自变量与因变量之间的相关程度)

mean_absolute_error(y_true,y_pred,sample_weight=None,
multioutput=‘uniform_average’)：
平均绝对误差

mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=‘uniform_average’)：均方差

median_absolute_error(y_true, y_pred) 中值绝对误差

r2_score(y_true, y_pred,sample_weight=None,multioutput=‘uniform_average’) ：R平方值
```

**分类指标**

```python
accuracy_score(y_true,y_pre) : 精度

auc(x, y, reorder=False) : ROC曲线下的面积;较大的AUC代表了较好的performance。

average_precision_score(y_true, y_score, average=‘macro’, sample_weight=None):根据预测得分计算平均精度(AP)

brier_score_loss(y_true, y_prob, sample_weight=None, pos_label=None):The smaller the Brier score, the better.

confusion_matrix(y_true, y_pred, labels=None, sample_weight=None):通过计算混淆矩阵来评估分类的准确性 返回混淆矩阵

f1_score(y_true, y_pred, labels=None, pos_label=1, average=‘binary’, sample_weight=None): F1值
　　F1 = 2 * (precision * recall) / (precision + recall) precision(查准率)=TP/(TP+FP) recall(查全率)=TP/(TP+FN)

log_loss(y_true, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None)：对数损耗，又称逻辑损耗或交叉熵损耗

precision_score(y_true, y_pred, labels=None, pos_label=1, average=‘binary’,) ：查准率或者精度； precision(查准率)=TP/(TP+FP)

recall_score(y_true, y_pred, labels=None, pos_label=1, average=‘binary’, sample_weight=None)：查全率 ；recall(查全率)=TP/(TP+FN)

roc_auc_score(y_true, y_score, average=‘macro’, sample_weight=None)：计算ROC曲线下的面积就是AUC的值，the larger the better

roc_curve(y_true, y_score, pos_label=None, sample_weight=None, drop_intermediate=True)；计算ROC曲线的横纵坐标值，TPR，FPR
　　TPR = TP/(TP+FN) = recall(真正例率，敏感度) FPR = FP/(FP+TN)(假正例率，1-特异性)
```

## （6）**关于分类中的混淆矩阵、ROC(AUC)曲线的解释**

**混淆矩阵（confusion matrix）是机器学习中用来总结分类模型预测结果的一个分析表，它以矩阵的形式描绘样本数据的真实属性和分类预测结果类型之间的关系。**

**模型分类的效果如何，就借助一些专门的评价指标。可用于评估分类模型预测效果的指标有准确率（accuracy）、精确率（precision）、召回率（recall）和F1值。**

 <img src="https://img-blog.csdnimg.cn/d80de1d1d0da4fa39b271b3a212a5796.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom: 33%;" />![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

<img src="https://img-blog.csdnimg.cn/3159441841fc428e869efa0d5023d233.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:33%;" />![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

混淆矩阵中，1）准确率（accuracy）是，被分对的样本数除以所有的样本数，对于分类均衡数据使用；2）准确度，表示被分为正例的示例中实际为正例的比例；3）召回率(recall)，召回率也叫查全率是覆盖面的度量，度量有多少个正例被分为正例。4）精度(precision)：反映测量结果与真值接近程度的量，它与误差的大小相对应，因此可用误差大小来表示精度的高低，误差小则精度高，误差大则精度低。5）F1-score如下：
$$
F1-score=2*[(precision*recall)/(precision+recall)]
$$

$$
accuracy=(TP+TN)/(TP+TN+FP+FN)
$$

**ROC曲线绘制的Python实现**

熟悉sklearn的读者肯定都知道，**几乎所有评估模型的指标都来自sklearn库下面的metrics**，包括计算召回率，精确率等。ROC曲线的绘制也不例外，都得先计算出评估的指标，也就是从metrics里面去调用roc_curve, auc，然后再去绘制。

```python
from sklearn.metrics import roc_curve, auc
```

roc_curve和auc的官方说明教程示例如下:

```python
# 数据准备
>>> import numpy as np
>>> from sklearn import metrics
>>> y = np.array([1, 1, 2, 2])
>>> scores = np.array([0.1, 0.4, 0.35, 0.8])

# roc_curve的输入为
# y: 样本标签
# scores: 模型对样本属于正例的概率输出
# pos_label: 标记为正例的标签，本例中标记为2的即为正例
>>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)
# 假阳性率
>>> fpr
array([ 0. ,  0.5,  0.5,  1. ])
# 真阳性率
>>> tpr
array([ 0.5,  0.5,  1. ,  1. ])
# 阈值
>>> thresholds
array([ 0.8 ,  0.4 ,  0.35,  0.1 ])

# auc的输入为很简单，就是fpr, tpr值
>>> auc = metrics.auc(fpr, tpr)
>>> auc
0.75

```

## （7）epoch和iteration的关系

iteration：1个iteration等于使用batchsize个样本训练一次；
epoch：1个epoch等于使用训练集中的全部样本训练一次；

比如要做100次iteration才等于做1次epoch训练。

## （8）baseline和benchmark是什么

1. 想强调一下，baseline 就只是「参照物」的意思，至于 baseline 系统是怎么来的、性能如何，并没有一定的标准。

比如：

- 如果你是机器学习的初学者，在做课程作业，那么你可能用「随机猜测」作为 baseline；如果你是要在顶会发论文，那么很可能就需要用当前最好的系统（称为 state of the art）来作 baseline，否则审稿人就会质疑。
- 如果你的论文的论点是「我针对某系统作了改进，提升了性能」，那么 baseline 就应该是未改进的系统（相当于生物实验中的「对照组」），它与改进后的系统只有一处不同，这样才能下结论说你的改进就是提升性能的原因。如果你的论文的论点是「我提出的方法 A 比已有的方法 B 更好」，那么 baseline 就应该是方法 B，即使它跟方法 A 毫无关系。
- 当你选定了一个 baseline 系统后，如果你能联系上作者，索取到他的代码，就可以直接用作者的实现作为 baseline；如果联系不上，就只能自己复现。有时候，你选择的 baseline 是你要研究的更广阔的框架下的一个特例，而你自己实现了框架下的其它方法，此时为了让系统之间只有一处不同，你可能会主动选择在框架下重新实现 baseline。
- 如果你是参加比赛，那么主办方常常会主动提供 baseline 系统。你可以在它的基础上做修改，也可以另起炉灶重新实现自己的系统。

2. 一个算法之所以被称为benchmark，是因为它的性能已经被广泛研究，人们对它性能的表现形式、测量方法都非常熟悉，因此可以作为标准方法来衡量其他方法的好坏。
   这里需要区别state-of-the-art（SOTA），能够称为SOTA的算法表明其性能在当前属于最佳性能。如果一个新算法以SOTA作为benchmark，这当然是最好的了，但如果比不过SOTA，能比benchmark要好，且方法有一定创新，也是可以发表的。

简而言之，
benchmark一般是和同行中比较牛的算法比较，比牛算法还好，那你可以考虑发好一点的会议/期刊；
baseline一般是自己算法优化和调参过程中自己和自己比较，目标是越来越好，当性能超过benchmark时，可以发表了，当性能甚至超过SOTA时，恭喜你，考虑投顶会顶刊啦。

## （9）交叉熵损失讲解

https://www.cnblogs.com/aijianiula/p/9460842.html

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221019201143145.png" alt="image-20221019201143145" style="zoom: 50%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221019201227306.png" alt="image-20221019201227306" style="zoom:67%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221019201251437.png" alt="image-20221019201251437" style="zoom:67%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221019201305931.png" alt="image-20221019201305931" style="zoom:50%;" />

## （10）backbone、head、neck等深度学习中的术语解释

我们在阅读文章的时候，经常看到backbone head neck 这一类的术语，但是我们可能并不知道是什么意思，这篇文章就是对这些术语进行解释：
**backbone：**

翻译为主干网络的意思，既然说是主干网络，就代表其是网络的一部分，那么是哪部分呢？这个主干网络大多时候指的是提取特征的网络，其作用就是提取图片中的信息，共后面的网络使用。这些网络经常使用的是resnet、VGG等，而不是我们自己设计的网络，因为这些网络已经证明了在分类等问题上的特征提取能力是很强的。在用这些网络作为backbone的时候，都是直接加载官方已经训练好的模型参数，后面接着我们自己的网络。让网络的这两个部分同时进行训练，因为加载的backbone模型已经具有提取特征的能力了，在我们的训练过程中，会对他进行微调，使得其更适合于我们自己的任务。
**head：**

head是获取网络输出内容的网络，利用之前提取的特征，head利用这些特征，做出预测。


**neck:**

是放在backbone和head之间的，是为了更好的利用backbone提取的特征。


**bottleneck:**

瓶颈的意思，通常指的是网络输入的数据维度和输出的维度不同，输出的维度比输入的小了许多，就像脖子一样，变细了。经常设置的参数 bottle_num=256，指的是网络输出的数据的维度是256 ，可是输入进来的可能是1024维度的。


**GAP：**

在设计的网络中经常能够看到gap这个层，我之前不知道是干啥的，后了解了，就是Global Average Pool全局平均池化，就是将某个通道的特征取平均值，经常使用AdaptativeAvgpoold(1),在pytorch中，这个代表自适应性全局平均池化，说人话就是将某个通道的特征取平均值。

```text
 self.gap = nn.AdaptiveAvgPool2d(1)
```


**Embedding**:

深度学习方法都是利用使用线性和非线性转换对复杂的数据进行自动特征抽取，并将特征表示为“向量”（vector），这一过程一般也称为“嵌入”（embedding）

**pretext task和downstream task：**
用于预训练的任务被称为前置/代理任务(pretext task)，用于微调的任务被称为下游任务(downstream task)


**temperature parameters**

在论文中经常能看到这个温度参数的身影，那么他都有什么用处呢？比如经常看到下面这样的式子：

![img](https://pic2.zhimg.com/80/v2-d4fb5e799ec69cdd2d2716df320d2485_720w.webp)


里面的beta就是temperature parameter，他在运算的时候起到什么作用呢？是这样的，他可以起到平滑softmax输出结果的作用，举例子如下：

```text
import torch
x = torch.tensor([1.0,2.0,3.0])
y = torch.softmax(x,0)
print(y)
 
x1 = x / 2  # beta 为2
y = torch.softmax(x1,0)
print(y)
 
x2 = x/0.5  # beta 为0.5
y = torch.softmax(x2,0)
print(y)
```


输出结果如下：

```text
tensor([0.0900, 0.2447, 0.6652])
tensor([0.1863, 0.3072, 0.5065])
tensor([0.0159, 0.1173, 0.8668])
```


当beta>1的时候，可以将输出结果变得平滑，当beta<1的时候，可以让输出结果变得差异更大一下，更尖锐一些。如果beta比较大，则分类的crossentropy损失会很大，可以在不同的迭代次数里，使用不同的beta数值，有点类似于学习率的效果。

**热身Warm up**

Warm up指的是用一个小的学习率先训练几个epoch，这是因为网络的参数是随机初始化的，一开始就采用较大的学习率容易数值不稳定。

**end to end**

在论文中经常能遇到end to end这样的描述，那么到底什么是端到端呢？其实就是给了一个输入，我们就给出一个输出，不管其中的过程多么复杂，但只要给了一个输入，机会对应一个输出。比如分类问题，你输入了一张图片，肯呢个网络有特征提取，全链接分类，概率计算什么的，但是跳出算法问题，单从结果来看，就是给了一张输入，输出了一个预测结果。End-To-End的方案，即输入一张图，输出最终想要的结果，算法细节和学习过程全部丢给了神经网络。


**domain adaptation 和domain generalization 域适应和域泛化**
域适应中，常见的设置是源域D_S完全已知，目标域D_T有或无标签。域适应方法试着将源域知识迁移到目标域。第二种场景可以视为domain generalization域泛化。这种更常见因为将模型应用到完全未知的领域，正因为没有见过，所以没有任何模型更新和微调。这种泛化问题就是一种开集问题，由于所需预测类别较多，所以比较头疼 。

## （11）高斯混合模型（GMM）

https://zhuanlan.zhihu.com/p/30483076



















#               三、迁移学习相关知识

## 3.1 迁移学习问题集锦

### （1）

## 3.2 零样本学习问题集锦

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220913112157105.png" alt="image-20220913112157105" style="zoom:50%;" />





# 三、数据分析相关知识

## 1. 特征选择

**关于数据挖掘的五大流程：①获取场景数据集；②数据预处理：从数据中检测，纠正或删除损坏，不准确或不适用于模型的记录的过程。**可能面对的问题有：数据类型不同，比如有的是文字，有的是数字，有的含时间序列，有的连续，有的间断。数据预处理的目的是让数据适应模型，匹配模型的需求。**③特征工程：将原始数据转换为更能代表预测模型的潜在问题的特征的过程，可以通过挑选最相关的特征，提取特征以及创造特征来实现，其中创造特征又经常以降维算法的方式实现。**可能面对的问题有：特征之间有相关性，特征和标签无关，特征太多或太小，或者干脆就无法表现出应有的数据现象或无法展示数据的真实面貌。**特征工程的目的：1）降低计算成本；2）提升模型上线。④建模：测试模型并预测出结果；⑤上线：验证模型效果。**

**在机器学习中，如果算法只能处理数值数据，因此需要将文字等转换成数据表现。因此，出现了编码与哑变量（OrdinalEncoder, OneHotEncoder）方式。**

对于SVM、PCA、Kmeans都已单独写了文章。

**特征选择主要有：Filter过滤法（方差过滤、相关性过滤）；Embedded嵌入法；Wrapper包装法；降维算法**。

在业务过程中，可能会遇到很多特征，这些特征不能仅限于依赖业务的理解来进行选择，因此可以选择“特征选择”方法选择特征。

**1. Filter过滤法**

过滤方法通常用作预处理步骤，特征选择完全独立于任何机器学习算法，它是根据各种统计检验中的分数以及相关性的各项指标来选择特征。

![img](https://img-blog.csdnimg.cn/e3ee7d5fe07043a58ca19b0324bbe237.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

 **①方差过滤**

这是通过特征本身的方差来筛选特征的类。比如一个特征本身的方差很小，就表示样本在这个特征上基本没有差异，可能特征中的大多数值都一样，甚至整个特征的取值都相同，那这个特征对于样本区分没有任何作用。**所以无论接下来的特征工程要做什么，都要优先消除方差为0的特征**。VaricanceThreshold有重要参数threshold，表示方差的阈值，表示舍弃所有方差小于threshold的特征，不填的时候默认为0，即删除所有记录都相同的特征。

![img](https://img-blog.csdnimg.cn/574e62b954914c77afb3465ae65c497b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

 可以看见，我们已经删除了方差为0的特征，但是依然剩下了708多个特征，明显还需要进一步的特征选择。然而，如果我们知道我们需要多少个特征，方差也可以帮助我们将特征选择一步到位。比如说，**我们希望留下一半的特征，那可以设定一个让特征总数减半的方差阈值，只要找到特征方差的中位数，再将这个中位数作为参数threshold的值输入就好了**。

![img](https://img-blog.csdnimg.cn/42186bb9586b47cdb59b09641fdfe84c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

 为什么随机森林运行如此之快？为什么方差过滤对随机森林没很大的有影响？这是由于两种算法的原理中涉及到的计算量不同。最近邻算法KNN，单棵决策树，支持向量机SVM，神经网络，回归算法，都需要遍历特征或升维来进行运算，所以他们本身的运算量就很大，需要的时间就很长，因此方差过滤这样的特征选择对他们来说就尤为重要。但对于不需要遍历特征的算法，比如随机森林，它随机选取特征进行分枝，本身运算就非常快速，因此特征选择对它来说效果平平。这其实很容易理解，无论过滤法如何降低特征的数量，随机森林也只会选取固定数量的特征来建模；而最近邻算法就不同了，特征越少，距离计算的维度就越少，模型明显会随着特征的减少变得轻量。因此，过滤法的主要对象是：需要遍历特征或升维的算法们，而过滤法的主要目的是：在维持算法表现的前提下，帮助算法们降低计算成本。

 **②相关性过滤**

**方差挑选完毕之后，就要考虑特征的相**关性。我们希望能够选出与标签相关且有意义的特征，因为这样的特征能够为我们提供大量的信息，在sklearn中，我们有三种常用的方法来评判特征与标签之间的相关性：**卡方，F检验， 互信息**。

卡方过滤：

卡方过滤是专门针对离散型标签（即分类问题）的相关性过滤。卡方检验类feature_selection.chi2计算每个非负特征和标签之间的卡方统计量，并按照卡方统计量由高到低为特征排名。

另外，如果卡方检验检测到某个特征中所有的值都相同，会提示我们使用方差先进行方差过滤。

![img](https://img-blog.csdnimg.cn/f76fd9bed98a4b4394a059778c994d46.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

 F检验：

<img src="https://img-blog.csdnimg.cn/6a49baf6c843429ca036a5d62bda8e14.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

 <img src="https://img-blog.csdnimg.cn/603683f22b4d437f8c4a2cce6283ec94.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

 互信息法：

<img src="https://img-blog.csdnimg.cn/3e308b22a879471d986896c00e4c5247.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

 **通常来说，我会建议，先使用方差过滤，然后使用互信息法来捕捉相关性。**

**2. Embedded嵌入法**

<img src="https://img-blog.csdnimg.cn/37a1f2f5798344f6a8240022bc6c21d5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

 **3. Wrapper包装法**

<img src="https://img-blog.csdnimg.cn/2e58eeed38124a3ab4fa0cb28c0a3229.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

  <img src="https://img-blog.csdnimg.cn/fa9fb9e770cd411ab72fb3c6857c49f1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6L2p6KW_6ZOO,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom: 67%;" />![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

# 四、各种数学相关知识

## 4.1 直方图与柱状图

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220915211900505.png" alt="image-20220915211900505" style="zoom: 33%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220915211914674.png" alt="image-20220915211914674" style="zoom: 33%;" />

## 4.2 笛卡尔积

笛卡尔乘积是指在数学中，两个[集合](https://baike.baidu.com/item/集合?fromModule=lemma_inlink)*X*和*Y*的笛卡尔积（Cartesian product），又称[直积](https://baike.baidu.com/item/直积/6537064?fromModule=lemma_inlink)，表示为*X* × *Y*，第一个对象是*X*的成员而第二个对象是*Y*的所有可能[有序对](https://baike.baidu.com/item/有序对?fromModule=lemma_inlink)的其中一个成员。
$$
表达式：A×B = {(x,y)|x∈A∧y∈B}
$$






#             五、专业相关欠缺知识

## 5.1 时域转频域

### 时域：事件按照时间的先后顺序发生。顾名思义就是随着时间的推移，我们所能直观感受到的东西或事物。

横轴：时间

纵轴：震动幅度（音量的高低）

**采样频率**：（单位是HZ）是指将模拟声音波形进行数字化时，每秒钟抽取声波幅度样本的次数。通俗的讲采样频率是指计算机单位时间内能够采集多少个信号样本。

采样频率的选择应该遵循**奈奎斯特**（Harry Nyquist）采样理论：如果对某一模拟信号进行采样，则采样后可还原的最高信号频率只有采样频率的一半，或者说只要采样频率高于输入信号最高频率的两倍，就能从采样信号系列重构原始信号。**正常人听觉的频率范围大约在20Hz~20kHz之间**，**根据奈奎斯特采样理论，为了保证声音不失真，采样频率应该在40kHz左右**。常用的音频采样频率有8kHz、11.025kHz、22.05kHz、16kHz、37.8kHz、44.1kHz、48kHz等，如果采用更高的采样频率，还可以达到DVD的音质。

傅立叶告诉我们，任何周期函数都可以看作不同振幅，不同相位的正弦波的叠加。贯穿时域和频域的方法之一，就是傅立叶分析，傅立叶分析又分为两个部分：傅立叶级数和傅立叶变换。

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220927195847355.png" alt="image-20220927195847355" style="zoom:50%;" />

<img src="F:\微信保存文件\WeChat Files\lianpenglong\FileStorage\File\2022-10\Page1.jpg" alt="Page1" style="zoom: 25%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221010112448788.png" alt="image-20221010112448788" style="zoom:50%;" />

### 频域：

通过傅里叶变换可以把信号从时域转换到频域；（将时域的信号（信号可以是周期与非周期信号）变成频域形式并加以分析的方法称为频谱分析。其目的是把复杂的时域波形，经过某种变换分解为若干单一的谐波分量来研究，以获得信号的频率结构以及各谐波和相位信息。这某种变换可以是傅立叶级数，也可以是傅立叶变换进行变换，这两者目的都一样，都是把时域信号变成频域以便于信号分析）

之前一直不理解频域里的频谱取值是怎么来的，后来发现它是和时域里的采样率相对应的，单位都是HZ， 时域如果1s采样 16000HZ， 转换到频域的频率范围就是（0， 16000HZ），相当于这1s 内的波形可以由这 16000个不同的正玄波叠加而成。

**短时傅里叶变换（窗式傅里叶变换）**

如果把一段音频直接FFT，因为时间较长，不能有效的逼近时域信号，会使信号太过平滑，于是又有了短时傅里叶变换 stft，用窗口滑动进行 FFT, 比如20ms 一次，相邻之间可以有重叠;

基本思想：局部平稳化-把长的非平稳随机过程看成是一系列短时随机平稳信号的叠加，短时性可通过在时间上加窗口函数实现（即截取一部分源数据）。通过该方法，人们至少可以说，无论发现了什么频率成分，它一定是发生在信号被截取的某个特定时间段内。

可用的函数：librosa.stft( )，音频处理库 librosa 很强大，可输出各种频谱。



### 时域信号与频域信号的关系

无论是连续的还是非连续的，周期信号用傅立叶级数来表示，非周期信号用傅立叶变换来表示；

时域信号是连续非周期的，则傅立叶变换后频域信号是连续非周期的；

时域信号是连续周期的，则傅立叶级数变换后频域信号是离散非周期的；

时域信号是离散的非周期时间信号，则DTFT之后，其频谱是连续的周期函数；

时域信号是离散的周期时间信号，则DTFT之后，其频谱是离散的周期函数。

<img src="https://img-blog.csdnimg.cn/20200815163417485.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NTU0OTY0,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:50%;" />

离散时间信号的傅立叶变换DTFT

像模拟信号一样，采样信号或数字信号序列也存在着傅里叶变换，通常称作离散时间信号的傅里叶变换，即DTFT；
对连续时间信号在时域内进行采样的结果是频域内频谱的周期延拓，也就是说采样序列的频谱是周期函数，它可以用傅里叶级数表示，傅里叶级数的稀疏就相当于采样序列，因此把一般序列x(n)的DTFT定义为：

DTFT的逆变换为：

<img src="https://img-blog.csdnimg.cn/20200815164248358.png#pic_center" alt="img" style="zoom:50%;" />

DTFT中的级数求和不一定总是收敛的，若x(n)绝对可和，则该级数绝对收敛（充分条件）

### 傅立叶变换、拉普拉斯变换、z变换的联系是什么？

傅里叶变换需要满足一个条件，即所谓的狄利克雷条件（要求信号绝对可积/绝对可和），为了始补，满足这一条件的信号，也能读出它的频率，拉普拉斯变换和Z变换，对频率的含义做出了扩充，使得大多数有用信号都具有了对应的“频率”域表达式，方便对各个器件的设计。

这里，我们并不是通过拉氏变换和Z变换获取不满足狄利克雷条件的函数的傅氏变换。事实上由于收敛域的问题，这些函数的傅氏变换是不收敛的，即使通过拉氏变换和Z变换也不可能获得这些函数的傅氏变换。
**拉氏变换和Z变换的意义，是将频率域的某些限制条件A，转化为复频率域中与之等价的相应条件A’，然后在复频域内直接观察信号或系统的拉氏变换或Z变换，看X(s)或X(z)是否满足条件A’，得到相应的结论。**用这个结论代替傅里叶变换的结论（因为傅里叶变换不存在，无法得出结论）。

他们之间的关系到底是什么？
首先，傅里叶变换粗略分来包括连续时间傅里叶变换（CTFT）、离散时间傅里叶变换（DTFT）。
**CTFT是将连续时间信号变换到频域，将频率的含义扩充之后，就得到拉普拉斯变换。**
**DTFT是将离散时间信号变换到频域，将频率的含义扩充之后，就得到Z变换。**

Z变换：
序列x(n)的z变换定义为:
<img src="https://img-blog.csdnimg.cn/20200815165450450.png#pic_center" alt="img" style="zoom:50%;" /> 

## 5.2 扭矩、力矩

![img](https://bkimg.cdn.bcebos.com/pic/738b4710b912c8fc53d1f052fa039245d688210a?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5/format,f_auto)

力矩在物理学里是指作用力使物体绕着转动轴或支点转动的趋向。力矩，力对物体产生转动作用的物理量，可以分为力对轴的矩和力对点的矩。转动力矩又称为转矩或扭矩。

![img](https://pic2.zhimg.com/80/v2-12c65dbc570007bba456749cbab8c039_720w.jpg)

力矩的概念在我们日常生活中随处可见，从小时候玩过的跷跷板，到阿基米德的名人名言——“给我一个支点，我将撬动整个地球”，这些都体现着力矩的含义。同样，在汽车上力矩也是无处不在，只不过通过一系列的传动轴的旋转，这里的力矩称之为扭矩。扭矩的大小直接影响着动力输出的工作效率、能源消耗、甚至运转寿命及安全性能等等因素。

**力矩与转矩的区别：**

二者所涵盖的范围不同，力矩的范围更宽泛，一切力乘以力臂的结果都可以称之为力矩，但是转矩一般指旋转的物体所受到的力矩。举例来说，车轮旋转时，地面摩擦力与车轮半径的乘积一般称之为转矩，但是也是力矩的一种。而用瓶起子开啤酒瓶一般称之为力矩，而不能说是转矩。

**转矩与扭矩的区别：**

使机器元件转动（包括有转动倾向）的力偶或力矩叫转动力矩，简称转矩。任何元件在转矩的作用下，必定产生某种程度的扭转变形（可能包括弹性变形和塑性变形）。因此，习惯上又常把转动力矩叫扭转力矩，简称扭矩。二者可以在任何领域混用，但扭矩在工程技术上用的更普遍些。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 

**电机功率、转速、输出扭矩之间的关系推导**

![image-20220922173300427](C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220922173300427.png)

## 5.3 采样频率

采样频率也称为采样速度或者采样率，定义了单位时间内从连续信号中提取并组成离散信号的采样个数，用Hz来表示。采样频率的倒数是采样周期或者叫采样时间，它是采样之间的时间间隔。通俗来讲，采样频率是指计算机单位时间内能够采集多少个信号样本。

对于信号采样的过程，我们需要遵循乃奎斯特采样定律，采样频率应大于信号最高频率的两倍。

## 5.4 异常检测与故障诊断的区别

异常检测就是寻找不符合期望行为的数据异常点或者离群点。在现实世界中有着广泛的应用场景，例如信用卡欺诈检测，保险欺诈检测，医疗健康辅助诊断，网络入侵检测，安全关键系统错误检测，军事侦察等。在异常检测中，由于异常点少之又少，大部分是正常样本，异常只是相对小概率事件，并且异常点的特征表现非常不集中，即异常种类非常多，千奇百怪，即正常的情况大同小异，而异常各不相同，这种情况用有限的正例样本（异常点）训练有监督模型学习就很难从中学到有效的规律，再加上异常数据往往是比较难获得的，所以异常检测往往用无监督学习或半监督学习方法来进行。

故障诊断主要是为了定位系统的故障，并判断出故障发生的位置，发生原因，以及帮助进行如何恢复的决策。应用故障诊断需要对诊断目标的机理比较了解，从而建立出模型，进而通过收集数据进行数据处理，分析，与诊断故障，工业上应用比较多的是用于诊断某个机械设备的故障。故障诊断发展的大方向是故障预测、PHM、孪生模型的故障诊断和预测等。

## 5.5 一次设备和二次设备 

一次设备是指直接用于生产、输送和分配电能的生产过程的高压电气设备。它包括发电机、变压器、断路器、隔离开关、自动开关、接触器、刀开关、母线、输电线路、电力电缆、电抗器、电动机等。二次设备是指对一次设备的工作进行监测、控制、调节、保护以及为运行、维护人员提供运行工况或生产指挥信号所需的低压电气设备。如熔断器、按钮、指示灯、控制开关、继电器、控制电缆、仪表、信号设备、自动装置等。
生产和转换电能的设备:如将机械能转换成电能的发电机、变换电压、传输电能的变压器，将电能变成机械能的电动机等。接通和断开电路的开关设备:如高低压断路器、负荷开关、熔断器、隔离开关、接触器、磁力启动器等。保护电气:如限制短路电流的电抗器、防御过电压的避雷器等。载流导体:如传输电能的软、硬导体及电缆等。



# 六、博士课题

![image-20221028181731066](C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221028181731066.png)

## 6.0 智能故障诊断学术期刊



 ![img](https://pic1.zhimg.com/v2-5778a0feb2078b3e47a22b04f19aaa2e_720w.jpg?source=d16d100b)

![img](https://picx1.zhimg.com/v2-b7ccdd05632fe4ca99f3365f45297a4c_720w.jpg?source=d16d100b)

![img](https://picx1.zhimg.com/v2-1d6823d0377cafd24ed3458a3e4214f0_720w.jpg?source=d16d100b)

![img](https://pic1.zhimg.com/v2-77bdf6fac2a4eacbb00a59d69ef6bccb_720w.jpg?source=d16d100b)

![img](https://pic1.zhimg.com/v2-3d932f56a4111126b466f3c0774d93bb_720w.jpg?source=d16d100b)

![img](https://picx1.zhimg.com/v2-fb67e5a9f409843d8c80d260fd13bf32_720w.jpg?source=d16d100b)

![img](https://picx1.zhimg.com/v2-b61292089209a6a411408f348f820ace_720w.jpg?source=d16d100b)

![img](https://pica.zhimg.com/v2-d53e646771eeb6fc724ee24445744653_720w.jpg?source=d16d100b)

![img](https://picx1.zhimg.com/v2-6ca53f01f03ccd70ee8dfbb4809b5420_720w.jpg?source=d16d100b)



## 6.1 数据集分析

### （1）

HP是是工程技术上常用的一种计量功率的单位。英文单词horsepower的缩写，中文名马力，别称匹，实用的范围是：汽车工业/内燃机/空调。一般HP是指公制马力而不是英制马力。

## 6.2 模型分析

### 6.2.1 开放集模型



## 6.3 实验结果分析

### （1）多分类混淆矩阵

在多分类任务中，可用混淆矩阵来比较分类结果与实际测得值，从而直观地表示各类别的分类状态，多分类混淆矩阵如图所示。

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220922200021322.png" alt="image-20220922200021322" style="zoom: 67%;" />

混淆矩阵列代表预测值为某一个类别，行代表真实标签为某一个类别。对于某类别而言，可将用户按真实标签与预测标签分为真阳性(True Positive, TP)、假阳性(False Positive, FP)、真阴性(True Negative, TN)与假阴性(False Negative, FN)。TP表示将此类别用户正确地预测出来；FP表示将非此类别的用户错误地预测为此类别；TN表示将非此类别的用户正确地预测为非此类别；FN表示将此类别用户错误地预测为非此类别。 

以混淆矩阵为基础，可得分类器的多个评价指标，二分类中常用指标包括准确率(Accuracy, ACC)、精确度(Precision, PRE)、查全率 Recall和 F1分数(F1-Score, F1)。其中 ACC为所预测样本中预测正确的比例；PRE为所有预测为某类别的用户中实际为此类用户的占比；Recall为所有实际为某类别的用户中预测为此类用户的占比；F1为与 PRE和 Recall有关的综合指标。各指标计算式分别如下：

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220922200251728.png" alt="image-20220922200251728" style="zoom: 67%;" />

在计算多分类的评价指标时，需将 n分类拆分为 n个二分类进行计算，即可得到各个类别的评价指标结果。将各个类别的结果进行平均可得分类任务的整体指标，其中平均方式有两种，即宏平均(Macro average)与微平均(Micro average)。宏平均是将 n个二分类的各指标结果直接求算数平均值，微平均则为 n个二分类结果的 TP、FP、TN与 FN值对应相加，再根据各指标算式进行计算。**宏平均在计算的过程中不考虑各个类别的样本比例，因此不适合数据集不平衡的情况，所以本文选用微平均作为多分类结果的计算方式。**使用 microA、microP、microR、microF1分别表示多分类结果各类别准确率、精确度、召回率与 F1分数的平均值，各指标计算式与二分类时 ACC、PRE、Recall和 F的计算式形式相同，但变量含义不同，需将分类结果中每个类别的 TP、FP、TN与 FN样本数相加再进行计算。

 **多类别混淆矩阵的推导及程序****（例子）**

1. **假如有以下数据**

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220923212634707.png" alt="image-20220923212634707" style="zoom: 50%;" />

可以看出，上表为一份样本量为9，类别数为3的含标注结果的三分类预测样本。TN对于准召的计算而言是不需要的，因此下面的表格中未统计该值。

① 按照定义计算Precision、Recall
1. 对于类别A

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220923213315039.png" alt="image-20220923213315039" style="zoom:50%;" />

2. 对于类别B

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220923213416353.png" alt="image-20220923213416353" style="zoom:50%;" />

3. 对于类别C

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220923213447103.png" alt="image-20220923213447103" style="zoom:50%;" />

2. **调用sklearn的api进行验证**

```python
from sklearn.metrics import classification_report
from sklearn.metrics import precision_score, recall_score, f1_score

true_lable = [0, 0, 0, 0, 1, 1, 1, 2, 2] # 真实标签类别
prediction = [0, 0, 1, 2, 1, 1, 2, 1, 2]

measure_result = classification_report(true_lable, prediction)
print('measure_result = \n', measure_result)

#------------------打印结果
measure_result = 
               precision    recall  f1-score   support

           0       1.00      0.50      0.67         4
           1       0.50      0.67      0.57         3
           2       0.33      0.50      0.40         2

    accuracy                           0.56         9
   macro avg       0.61      0.56      0.55         9
weighted avg       0.69      0.56      0.58         9
```

3. **Micro-F1、Macro-F1、weighted-F1**

<img src="https://img-blog.csdnimg.cn/44e2b38ce0314309ba93450bec9eb849.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5b-N6ICF44Gu5Lmx5aSq6YOO,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:50%;" />

总的来说，微观F1(micro-F1)和宏观F1(macro-F1)都是F1合并后的结果，这两个F1都是用在多分类任务中的评价指标，是两种不一样的求F1均值的方式；**micro-F1和macro-F1的计算方法有差异**，得出来的结果也略有差异；

**①Micro-F1**

Micro-F1 不需要区分类别，直接使用总体样本的准召计算f1 score。

> 计算方法：先计算所有类别的总的Precision和Recall，然后计算出来的F1值即为micro-F1；
>
> 使用场景：在计算公式中考虑到了每个类别的数量，所以适用于数据分布不平衡的情况；但同时因为考虑到数据的数量，所以在数据极度不平衡的情况下，数量较多数量的类会较大的影响到F1的值；

该样本的混淆矩阵如下：

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220923214425420.png" alt="image-20220923214425420" style="zoom:50%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220923214458277.png" alt="image-20220923214458277" style="zoom:50%;" />

**②Macro-F1**

不同于micro f1，macro f1需要先计算出每一个类别的准召及其f1 score，然后通过求均值得到在整个样本上的f1 score。

> - 计算方法：将所有类别的Precision和Recall求平均，然后计算F1值作为macro-F1；
> - 使用场景：没有考虑到数据的数量，所以会平等的看待每一类（因为每一类的precision和recall都在0-1之间），会相对受高precision和高recall类的影响较大；

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220923214645655.png" alt="image-20220923214645655" style="zoom:50%;" />

**③weighted-F1**

除了micro-F1和macro-F1，还有weighted-F1，是一个将F1-score乘以该类的比例之后相加的结果，也可以看做是macro-F1的变体吧。

weighted-F1和macro-F1的区别在于：macro-F1对每一类都赋予了相同的权重，而weighted-F1则根据每一类的比例分别赋予不同的权重。

4. **指标的选择问题**

“我们看到，对于 Macro 来说， 小类别相当程度上拉高了 Precision 的值，而实际上， 并没有那么多样本被正确分类，考虑到实际的环境中，真实样本分布和训练样本分布相同的情况下，这种指标明显是有问题的， 小类别起到的作用太大，以至于大样本的分类情况不佳。 而对于 Micro 来说，其考虑到了这种样本不均衡的问题， 因此在这种情况下相对较佳。

总的来说， **如果你的类别比较均衡，则随便； 如果你认为大样本的类别应该占据更重要的位置， 使用Micro； 如果你认为小样本也应该占据重要的位置，则使用 Macro**； 如果 Micro << Macro ， 则意味着在大样本类别中出现了严重的分类错误； 如果 Macro << Micro ， 则意味着小样本类别中出现了严重的分类错误。

**为了解决 Macro 无法衡量样本均衡问题，一个很好的方法是求加权的 Macro， 因此 Weighed F1 出现了**。”

5. **代码问题**

```python
#------------------------------
#--------数据01--------------
#---------------------------
true_lable = [0, 0, 0, 0, 1, 1, 1, 2, 2]
prediction = [0, 0, 1, 2, 1, 1, 2, 1, 2]

from sklearn.metrics import classification_report
from sklearn.metrics import precision_score, recall_score, f1_score

true_lable = [0, 0, 0, 0, 1, 1, 1, 2, 2]
prediction = [0, 0, 1, 2, 1, 1, 2, 1, 2]


measure_result = classification_report(true_lable, prediction)
print('measure_result = \n', measure_result)

print("----------------------------- precision（精确率）-----------------------------")
precision_score_average_None = precision_score(true_lable, prediction, average=None)
precision_score_average_micro = precision_score(true_lable, prediction, average='micro')
precision_score_average_macro = precision_score(true_lable, prediction, average='macro')
precision_score_average_weighted = precision_score(true_lable, prediction, average='weighted')
print('precision_score_average_None = ', precision_score_average_None)
print('precision_score_average_micro = ', precision_score_average_micro)
print('precision_score_average_macro = ', precision_score_average_macro)
print('precision_score_average_weighted = ', precision_score_average_weighted)

print("\n\n----------------------------- recall（召回率）-----------------------------")
recall_score_average_None = recall_score(true_lable, prediction, average=None)
recall_score_average_micro = recall_score(true_lable, prediction, average='micro')
recall_score_average_macro = recall_score(true_lable, prediction, average='macro')
recall_score_average_weighted = recall_score(true_lable, prediction, average='weighted')
print('recall_score_average_None = ', recall_score_average_None)
print('recall_score_average_micro = ', recall_score_average_micro)
print('recall_score_average_macro = ', recall_score_average_macro)
print('recall_score_average_weighted = ', recall_score_average_weighted)

print("\n\n----------------------------- F1-value-----------------------------")
f1_score_average_None = f1_score(true_lable, prediction, average=None)
f1_score_average_micro = f1_score(true_lable, prediction, average='micro')
f1_score_average_macro = f1_score(true_lable, prediction, average='macro')
f1_score_average_weighted = f1_score(true_lable, prediction, average='weighted')
print('f1_score_average_None = ', f1_score_average_None)
print('f1_score_average_micro = ', f1_score_average_micro)
print('f1_score_average_macro = ', f1_score_average_macro)
print('f1_score_average_weighted = ', f1_score_average_weighted)

#---------------打印结果
measure_result = 
               precision    recall  f1-score   support

           0       1.00      0.50      0.67         4
           1       0.50      0.67      0.57         3
           2       0.33      0.50      0.40         2

    accuracy                           0.56         9
   macro avg       0.61      0.56      0.55         9
weighted avg       0.69      0.56      0.58         9

----------------------------- precision（精确率）-----------------------------
precision_score_average_None =  [1.         0.5        0.33333333]
precision_score_average_micro =  0.5555555555555556
precision_score_average_macro =  0.611111111111111
precision_score_average_weighted =  0.6851851851851852


----------------------------- recall（召回率）-----------------------------
recall_score_average_None =  [0.5        0.66666667 0.5       ]
recall_score_average_micro =  0.5555555555555556
recall_score_average_macro =  0.5555555555555555
recall_score_average_weighted =  0.5555555555555556


----------------------------- F1-value-----------------------------
f1_score_average_None =  [0.66666667 0.57142857 0.4       ]
f1_score_average_micro =  0.5555555555555556
f1_score_average_macro =  0.546031746031746
f1_score_average_weighted =  0.5756613756613757

Process finished with exit code 0


#------------------------------
#--------数据02--------------
#---------------------------
true_lable = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]
prediction = [3, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 1, 1, 1, 1, 1, 1, 3, 1, 2, 2, 2, 2, 2, 3, 0, 3, 3, 3, 3]

from sklearn.metrics import classification_report
from sklearn.metrics import precision_score, recall_score, f1_score

true_lable = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]
prediction = [3, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 1, 1, 1, 1, 1, 1, 3, 1, 2, 2, 2, 2, 2, 3, 0, 3, 3, 3, 3]

measure_result = classification_report(true_lable, prediction)
print('measure_result = \n', measure_result)

print("----------------------------- precision（精确率）-----------------------------")
precision_score_average_None = precision_score(true_lable, prediction, average=None)
precision_score_average_micro = precision_score(true_lable, prediction, average='micro')
precision_score_average_macro = precision_score(true_lable, prediction, average='macro')
precision_score_average_weighted = precision_score(true_lable, prediction, average='weighted')
print('precision_score_average_None = ', precision_score_average_None)
print('precision_score_average_micro = ', precision_score_average_micro)
print('precision_score_average_macro = ', precision_score_average_macro)
print('precision_score_average_weighted = ', precision_score_average_weighted)

print("\n\n----------------------------- recall（召回率）-----------------------------")
recall_score_average_None = recall_score(true_lable, prediction, average=None)
recall_score_average_micro = recall_score(true_lable, prediction, average='micro')
recall_score_average_macro = recall_score(true_lable, prediction, average='macro')
recall_score_average_weighted = recall_score(true_lable, prediction, average='weighted')
print('recall_score_average_None = ', recall_score_average_None)
print('recall_score_average_micro = ', recall_score_average_micro)
print('recall_score_average_macro = ', recall_score_average_macro)
print('recall_score_average_weighted = ', recall_score_average_weighted)

print("\n\n----------------------------- F1-value-----------------------------")
f1_score_average_None = f1_score(true_lable, prediction, average=None)
f1_score_average_micro = f1_score(true_lable, prediction, average='micro')
f1_score_average_macro = f1_score(true_lable, prediction, average='macro')
f1_score_average_weighted = f1_score(true_lable, prediction, average='weighted')
print('f1_score_average_None = ', f1_score_average_None)
print('f1_score_average_micro = ', f1_score_average_micro)
print('f1_score_average_macro = ', f1_score_average_macro)
print('f1_score_average_weighted = ', f1_score_average_weighted)

#-------------打印结果------
measure_result = 
               precision    recall  f1-score   support

           0       0.88      0.78      0.82         9
           1       0.86      0.75      0.80         8
           2       0.83      0.71      0.77         7
           3       0.56      0.83      0.67         6

    accuracy                           0.77        30
   macro avg       0.78      0.77      0.76        30
weighted avg       0.80      0.77      0.77        30

----------------------------- precision（精确率）-----------------------------
precision_score_average_None =  [0.875      0.85714286 0.83333333 0.55555556]
precision_score_average_micro =  0.7666666666666667
precision_score_average_macro =  0.7802579365079365
precision_score_average_weighted =  0.7966269841269841


----------------------------- recall（召回率）-----------------------------
recall_score_average_None =  [0.77777778 0.75       0.71428571 0.83333333]
recall_score_average_micro =  0.7666666666666667
recall_score_average_macro =  0.7688492063492064
recall_score_average_weighted =  0.7666666666666667


----------------------------- F1-value-----------------------------
f1_score_average_None =  [0.82352941 0.8        0.76923077 0.66666667]
f1_score_average_micro =  0.7666666666666667
f1_score_average_macro =  0.7648567119155354
f1_score_average_weighted =  0.7732126696832579

Process finished with exit code 0
```

### **多分类混淆矩阵画图**

图中纵轴是truth label，横轴是predicted label，那么第一行第一个0.6的含义是：模型分类正确的精度，每一行的和为100%。

### 多分类混淆矩阵最终的程序分析

<img src="F:\微信保存文件\WeChat Files\lianpenglong\FileStorage\File\2022-09\Page1(1).jpg" alt="Page1(1)" style="zoom: 28%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220927212734170.png" alt="image-20220927212734170" style="zoom: 50%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220927212802966.png" alt="image-20220927212802966" style="zoom: 50%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220927212817476.png" alt="image-20220927212817476" style="zoom: 50%;" />



## 6.4





# 七、学术软件使用

## 7.1 git使用

### （1）教程链接

https://www.bilibili.com/video/BV1Cr4y1J7iQ/?is_story_h5=false&p=1&share_from=ugc&share_medium=iphone&share_plat=ios&share_session_id=1E17EF54-5D8D-49B4-9FC5-BA9794F7CC23&share_source=WEIXIN&share_tag=s_i&timestamp=1663993522&unique_k=KHo38Nd&vd_source=96bd7e9a5befbf7a97d9f87e43c136de

Git是一个运行在你电脑上的版本控制软件，而Github是基于Git这个版本控制软件打造的网战。

#### 如何一步步安装及使用

具体参考：https://www.runoob.com/git/git-remote-repo.html

（1）git网站下载git客户端（如果没有github账户的去github网站注册）

https://git-scm.com/

（2）由于本地Git仓库和Github仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息:

```
$ ssh-keygen -t rsa -C "penglonglian@foxmail.com" # 邮箱需要修改为注册Github时的邮箱
# 之后会要求确认路径和输入密码，我们这使用默认的一路回车就行，成功的话会在C:\Users\lpl\.ssh中生成.ssh文件夹，进去打开id_rsa.pub，复制里面的pub（全部复制即可）
# 回到github上，进入Account => Settings （账户配置），左边选择 SSH and GPG keys，然后点击 New SSH key 按钮,title 设置标题，可以随便填，粘贴在你电脑上生成的 key。
# 添加成功后界面会显示自己配置成功
# 为了验证是否成功，可以输入以下命令
$ ssh -T git@github.com
The authenticity of host 'github.com (52.74.223.119)' can't be established.
RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes                   # 输入 yes
Warning: Permanently added 'github.com,52.74.223.119' (RSA) to the list of known hosts.
Hi tianqixin! You've successfully authenticated, but GitHub does not provide shell access. # 成功信息
# 以上命令说明我们已经成功连上了Github
# 之后就可以新建一个repository
# 创建之后就会在Quick setup-if you've done this kind of thing before下有一个SSH的类似于链接的东西（这个东西在提交的时候要用到）
```

```
# 要开始将自己文件夹下的.py等文件提交到自己的github了
$ git init
$ git add .
$ git commit -m "XXXX"

# 提交到github上
$ git remote add origin xxxxxxxxxxxxxxxx(创建的repository后产生的SSH类似于链接的东西)
$ git push -u origin master
```



### 2）使用过程中注意的命令

① 下载完的配置

```
git config --global user.name PancrasLPL
git config --global user.email lianpenglong@163.com
```

②两种命令

```
git clone   # 如果是从github上下载源码，可以使用git clone
# 比如想要让github上的文件下载到某个文件夹里/桌面上，就直接在相应的位置邮件打开Git bash here，然后git clone http...(github上的链接)
# 下载完之后会文件夹里会有一个.git文件，这个文件不需要操作
```

```
# 如果是自己的文件需要管理的时候，则需要新建一个文件夹，然后告诉git，帮我们管理它。
# 在自己想要管理的文件夹下右键Git bash here
# 然后输入git init, 相当于初始化
git init
# 接下来文件夹里立马创建了一个名为“.git”的隐藏文件夹，用来管理即将新建的源代码
# 除.git外的地方叫做工作区

# 接下来我们就需要将我们的文件提交给git仓库，即利用.git去帮助我们管理；但是不能直接操作.git文件
# 提交时有以下命令
git add . # .代表文件夹下所有的文件
git add main.py # 代表只提交main.py
# 上面的.代表当前文件夹的意思；表示将当前文件夹下的非空文件设置为准备提交的状态（子弹上膛，准备发射）
# 接下来就是提交
git commit -m "xxxx" # "xxx"这里面的内容是对本次提交的备注，eg."功能1已完成"

git log # 可以用git log来查看提交的历史记录
# 显示出来的一串东西其实就类似于身份证号
```

```
# 如果commit的文件有误，需要从上一次提交的进行恢复
git checkout HEAD xxx.py
# 如果把代码跑的乱七八糟的，也可以采用这种方式进行恢复
```

![image-20220929174348198](C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20220929174348198.png)

### （3）使用过程中出现的问题：

①：git clone出现 fatal: unable to access ‘https://github.com/...‘的两种解决方法

https://blog.csdn.net/weixin_45317091/article/details/113409909 （方法一）

②：OpenSSL SSL_read: Connection was reset, errno 10054的解决方法

https://blog.csdn.net/wjh1840226173/article/details/124355167

③：git commit提示nothing to commit, working tree clean

https://blog.csdn.net/milk_tiger/article/details/108546583

## 7.2 bibtex格式

是一种参考文献格式，纯文本的，你可以用记事本打开，里面的内容类似于Json一样的，一堆就是一个文献，等号前面是键，后面是值。很多文献管理软件打开这种格式后，想个数据库一样。

## 7.3 顶会

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221027092532516.png" alt="image-20221027092532516" style="zoom:50%;" />

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221027092544435.png" alt="image-20221027092544435" style="zoom:50%;" />

## 7.4 如何搜索期刊是不是EI

<img src="C:\Users\lpl\AppData\Roaming\Typora\typora-user-images\image-20221031093005943.png" alt="image-20221031093005943" style="zoom:50%;" />

## 7.5 Tensorflow和pytorch的gpu版本安装

https://zhuanlan.zhihu.com/p/524468331?utm_medium=social&utm_oi=654688221666086912&utm_psn=1570962513558265856&utm_source=wechat_session



https://zhuanlan.zhihu.com/p/495892407?utm_medium=social&utm_oi=654688221666086912&utm_psn=1570963126408904705&utm_source=wechat_session